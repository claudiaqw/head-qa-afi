Los sistemas preguntas/respuesta o de seleccion multiple, conocidos en inglés como Answer Selection, 

Que se adaptan a los datasets de manera que los sistemas pueden lograr alcanzar buenos resultados con un conocimiento muy superficial.

Los sistemas QA de múltiples opciones surgen para contrarrestar este efecto. 
Este tipo de conjunto de datos es muy escaso en áreas del conocimiento específicas como Medicina.

HEAD-QA: A Healthcare Dataset for Complex Reasoning presenta un complejo conjunto de datos de selección múltiple, que requiere conocimiento y razonamiento en dominios complejos y que, incluso para los huamnos, es una tarea difícil.

En este tipo de problemas de selección múltiple, un simple match de palabras no es suficiente.


## Descripcion del dataset


El conjunto de datos se puede representar como una lista de tuplas de la forma [(q0, A0), ..., (qn, An)] donde qi es una pregunta i y Ai el conjunto de respuestas para esa pregunta i. 

Este dataset a diferencia de otros de Q/A que se centran en el entendimiento del lenguaje requiere, Q/A requiere un razonamiento más profundo y conocimiento sobre materias específicas.

Este tipo de problema se considera más difícil de resolver que los sistemas Q/A comunes y el mejor performance alcanzado no está muy por encima de un clasificador aleatorio. 

## Métodos de control:

1. Random -> Multinomial
2. Blind -> Elegir la i-esima opción
3. Tamaño: Elegir la respuesta más larga

## Estado del adaptarse

### Sistemas Answer Selection

(2018, review on answer selection)

Un sistema Q/A típico consiste en:

1. Análisis de la pregunta
2. Recuperación de los documentos relevantes
3. Ordenamiento por relevancia y selección de las oraciones más relevantes a la pregunta
4. Extracción de la frase excata en lenguaje natural que responda a la pregunta


## Métodos:

### Recuperación de Información
Tratar el problema como un problema de Recuperación de Información. En un problema de recuperación de información tìpico, tendremos una consulta q y un conjunto de documentos D, siendo el objetivo: a partir de q obtener un ordenamiento de los documentos de acuerdo a la relevancia o nivel de similaridad con la consulta q. 
En este caso, por cada pregunta se construyen tantas queries como numero de opciones, de manera que una query q es el resultado de concatenar la pregunta y cada posible respuesta. la respuesta correcta es la query que más ala probabilidad alcanzó el documento en primer lugar.

### Cross-lingual
La mayor parte del trabajo en esta área ha sido en el idoma inglés. 
1. Cross-lingual information Retrieval: La misma idea de recuperación de información pero apliacada al dataset en inglés.
    * Multi-choice DrQA: 
    * Multi-choice BiDAF: 
    * Multi-choice DGEM and Decompatt


Los resultados mostraron que todos los sistemas obtuvieron un apuntuación muy inferior a los resultados alcanzados por los humanos , siendo los basados en redes neuronales, los de menor accuracy. La mejor approach fue la de recuperación de información. 


def _embed(self, query_tok, doc_tok):
        tokens_tensor, segments_tensors, sep_index = self._format_input(query_tok, doc_tok)

        self.model.eval()
        with torch.no_grad():
            last_hidden_state, pooled_output,_ = self.model(tokens_tensor, segments_tensors)

        last_hidden_state = last_hidden_state.squeeze(dim = 0)
        query_embed = last_hidden_state[1: sep_index]
        doc_embed = last_hidden_state[sep_index + 1:]

        query_embed = torch.sum(query_embed, dim = 0)
        doc_embed = torch.sum(doc_embed, dim=0)
        return query_embed, doc_embed







