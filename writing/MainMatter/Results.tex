\chapter{Resultados}\label{chapter:results}

A lo largo de esta tesis se han concebido y diseñado varios modelos para resolver la tarea de selección de respuestas a partir de un corpus previamente construido. En el presente capítulo, se expone un conjunto de experimentos desarrollados con el propósito de medir el desempeño de los modelos propuestos en dicha tarea. Asimismo, se verifica la validez del prototipo en función de los objetivos trazados al inicio de la investigación.

\section{Medidas de Evaluación}

Con el propósito de medir la eficacia de los modelos propuestos es necesario la aplicación de medidas estándares utilizadas en el paradigma del aprendizaje automático. Para la evaluación de los modelos propuestos se utiliza como métrica la \textbf{Exactitud}. Asimismo, teniendo en cuenta el escenario también se utiliza como métrica de evaluación la puntuación característica de estos exámenes y que es la empleada realmente para calificar los exámenes cada año.

Supongamos que estamos en presencia de un problema de clasificación binario cualquiera, donde solo existen dos clases que llamaremos $C^{+}$ y $C^{-}$. Los posibles tipos de respuestas de un modelo se definen como:

\begin{description}
  \item \textbf{\textit{True Positive} (TP)}: Un ejemplo se clasifica en \textbf{TP}, traducido al español como Verdadero Positivo, cuando la clase predicha coincide con la clase correcta $C^{+}$. En este caso, la predicción hecha fue correcta.
  \item \textbf{\textit{False Positive} (FP)}: Un ejemplo se clasifica en \textbf{FP}, en español Falso Positivo, cuando el valor predicho es $C^{+}$, sin embargo su valor correcto es $C^{-}$. En este caso, el modelo hizo una predicción equivocada.
  \item \textbf{\textit{False Negative} (FN)}: Una instancia se clasifica en \textbf{FN}, en español Falso Negativo, cuando el valor predicho es $C^{-}$, sin embargo su clase correcta es $C^{+}$. En este caso, como en el anterior, el modelo hizo una predicción incorrecta.
  \item \textbf{\textit{True Negative} (TN)}: Una instancia se clasifica en \textbf{TN}, en español, Verdadero Negativo, cuando la clase predicha corresponde con la clase correcta $C^{-}$, lo que implica que el modelo hizo una predicción acertada.
\end{description}

Estos tipos de respuestas se representan visualmente en la matriz de confusión que se muestra en la tabla \ref{tab:confusion}.

\begin{table}[h!]
  \caption{Matriz de confusión para un problema de clasificación binario}
  \begin{center}
    \begin{tabular}{ccc|cc|cc}
        & Valor Correcto/Valor Predicho &    & $\mathbf{C}^{\boldsymbol{+}}$ & & $\mathbf{C}^{\boldsymbol{-}}$  \\
        \hline
        & $\mathbf{C}^{\boldsymbol{+}}$ &   & TP & & FN  \\
        \hline
        & $\mathbf{C}^{\boldsymbol{-}}$ &   & FP & & TN  \\
    \end{tabular}
  \end{center}
  \label{tab:confusion}
\end{table}

La \textbf{Exactitud} (en inglés \textit{Accuracy}) se interpreta como la razón entre las predicciones correctas ($TP + TN$) y la cantidad total de instancias que analizó el modelo. Se computa sobre los resultados generales del modelo y se define como:

\begin{equation}
  E = \frac{TP + TN}{\textit{Total de Ejemplos}}
\end{equation}

La métrica estándar para calificar este tipo de exámenes consiste en sumar tres puntos si la respuesta está correcta y -1 si es incorrecta.

\section{Entrenamiento}

Dado que una instancia del conjunto original se convierte en varios ejemplos diferentes, una por cada posible respuesta y que solo una de las respuestas es correcta, el conjunto de datos resultante del procesamiento de texto es un conjunto desbalanceado. De manera general, por una instancia positiva pueden aparecer al menos 3 instancias negativas.

Se implementaron dos algoritmos de remuestreo.

\begin{itemize}
  \item \textit{Random Undersampling}: Eliminar del conjunto de datos transformados instancias negativas de manera aleatoria  hasta igualar la cantidad de instancias positivas y negativas.
  \item \textit{Random oversampling}: Proceso análogo al anterior pero adicionando instancias positivas al \textit{dataset} seleccionadas de manera aleatoria hasta igualar la cantidad de instancias de cada etiqueta.
\end{itemize}


\section{Evaluación de los modelos}

Se implementa un modelo de regresión logística, por su simplicidad se puede utilizar como \textit{baseline} supervisado 



\begin{table}[!tb]
  \begin{center}
    \caption{Comparación de los modelos por categorías por Puntos}
    \begin{tabular}{l|c|c|c|c|c}
      \textbf{Modelo} & \textbf{Biología} & \textbf{Enfermería} & \textbf{Farmacología} & \textbf{Medicina} & \textbf{Psicología} & \textbf{Química}\\
      \hline
      Regresión Logística & 1.132 & 452 & 1.132 & 452 & 452 & 1.132 & 452\\
      LSTM & 1.069 & 384 & 230 & 455 & 1.132 & 452 \\
      BiLSTM+Attn & 1.139 & 457 & 225 & 457 & 452 & 1.132 \\
      QA-LSTM & 1.149 & 455 & 231 & 463 & 231 & 463 \\
      QA-LSTM/CNN & 1.134 & 453 & 226 & 455 & 226 & 455 \\
      QA-BERT & 1.142 & 456 & 228 & 458 & 228 & 458 \\ 
      \textbf{Total} & \textbf{6.765} & \textbf{2.657} & \textbf{1.366} & \textbf{2.742}\\
    \end{tabular}
  \end{center}
  \label{comparison_points}
\end{table}


\begin{table}[!tb]
  \begin{center}
    \caption{Comparación de los modelos por categorías por Exactitud}
    \begin{tabular}{l|c|c|c|c|c}
      \textbf{Modelo} & \textbf{Biología} & \textbf{Enfermería} & \textbf{Farmacología} & \textbf{Medicina} & \textbf{Psicología} & \textbf{Química}\\
      \hline
      Regresión Logística & 1.132 & 452 & 1.132 & 452 & 452 & 1.132 & 452\\
      LSTM & 1.069 & 384 & 230 & 455 & 1.132 & 452 \\
      BiLSTM+Attn & 1.139 & 457 & 225 & 457 & 452 & 1.132 \\
      QA-LSTM & 1.149 & 455 & 231 & 463 & 231 & 463 \\
      QA-LSTM/CNN & 1.134 & 453 & 226 & 455 & 226 & 455 \\
      QA-BERT & 1.142 & 456 & 228 & 458 & 228 & 458 \\ 
      \textbf{Total} & \textbf{6.765} & \textbf{2.657} & \textbf{1.366} & \textbf{2.742}\\
    \end{tabular}
  \end{center}
  \label{comparison_acuracy}
\end{table}



\begin{table}[!tb]
  \begin{center}
    \caption{Exactitud y Puntos}
    \begin{tabular}{l|c|c|c|c|c}
      \textbf{Modelo} & \textbf{Exactitud Dev} & \textbf{Puntos Dev} & \textbf{Exactitud Test} & \textbf{Puntos Test} \\
      \hline
      Regresión Logística & 1.132 & 452 & 1.132 & 452\\
      LSTM & 1.069 & 384 & 230 & 455 \\
      BiLSTM+Attn & 1.139 & 457 & 225 & 457 \\
      QA-LSTM & 1.149 & 455 & 231 & 463 \\
      QA-LSTM/CNN & 1.134 & 453 & 226 & 455 \\
      QA-BERT & 1.142 & 456 & 228 & 458 \\ 
      \textbf{Total} & \textbf{6.765} & \textbf{2.657} & \textbf{1.366} & \textbf{2.742}\\
    \end{tabular}
  \end{center}
  \label{results_all}
\end{table}


\section{Análisis de los resultados}

Los algoritmos de clasificación, a diferencia de los algoritmos de regresión, durante el entrenamiento minimizan la función de pérdida seleccionada y no directamente la exactitud del modelo, aunque ambas estén relaciondas. De manera que el desempeño de un modelo, depende en gran medida de la función de pérdida seleccionada. 


Varias cosas que mejorar para la próxima:

- Otro enfoque
- Implementar otro método de remuestreo que utilice herramientas linguísticas externas y permita generar oraciones equivalentes
- Utilizar una función de pérdida que maximice la importancia de una respuesta correcta y penalice una incorrecta. Teniendo en cuenta ambos 
-



