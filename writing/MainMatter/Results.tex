\chapter{Resultados}\label{chapter:results}

A lo largo de esta tesis se han concebido y diseñado varios modelos para resolver la tarea de selección de respuestas a partir de un corpus previamente construido. En el presente capítulo, se expone un conjunto de experimentos desarrollados con el propósito de medir el desempeño de los modelos propuestos en dicha tarea. Asimismo, se verifica la validez del prototipo en función de los objetivos trazados al inicio de la investigación.

\section{Medidas de Evaluación}

Con el propósito de medir la eficacia de los modelos propuestos es necesario la aplicación de medidas estándares utilizadas en el paradigma del aprendizaje automático. Para la evaluación de los modelos propuestos se utiliza como métrica la \textbf{Exactitud}. Asimismo, teniendo en cuenta el escenario también se utiliza como métrica de evaluación la puntuación característica de estos exámenes y que es la empleada realmente para calificar los exámenes cada año.

Supongamos que estamos en presencia de un problema de clasificación binario cualquiera, donde solo existen dos clases que llamaremos $C^{+}$ y $C^{-}$. Los posibles tipos de respuestas de un modelo se definen como:

\begin{description}
  \item \textbf{\textit{True Positive} (TP)}: Un ejemplo se clasifica en \textbf{TP}, traducido al español como Verdadero Positivo, cuando la clase predicha coincide con la clase correcta $C^{+}$. En este caso, la predicción hecha fue correcta.
  \item \textbf{\textit{False Positive} (FP)}: Un ejemplo se clasifica en \textbf{FP}, en español Falso Positivo, cuando el valor predicho es $C^{+}$, sin embargo su valor correcto es $C^{-}$. En este caso, el modelo hizo una predicción equivocada.
  \item \textbf{\textit{False Negative} (FN)}: Una instancia se clasifica en \textbf{FN}, en español Falso Negativo, cuando el valor predicho es $C^{-}$, sin embargo su clase correcta es $C^{+}$. En este caso, como en el anterior, el modelo hizo una predicción incorrecta.
  \item \textbf{\textit{True Negative} (TN)}: Una instancia se clasifica en \textbf{TN}, en español, Verdadero Negativo, cuando la clase predicha corresponde con la clase correcta $C^{-}$, lo que implica que el modelo hizo una predicción acertada.
\end{description}

Estos tipos de respuestas se representan visualmente en la matriz de confusión que se muestra en la tabla \ref{tab:confusion}.

\begin{table}[h!]
  \caption{Matriz de confusión para un problema de clasificación binario}
  \begin{center}
    \begin{tabular}{ccc|cc|cc}
        & Valor Correcto/Valor Predicho &    & $\mathbf{C}^{\boldsymbol{+}}$ & & $\mathbf{C}^{\boldsymbol{-}}$  \\
        \hline
        & $\mathbf{C}^{\boldsymbol{+}}$ &   & TP & & FN  \\
        \hline
        & $\mathbf{C}^{\boldsymbol{-}}$ &   & FP & & TN  \\
    \end{tabular}
  \end{center}
  \label{tab:confusion}
\end{table}

La \textbf{Exactitud} (en inglés \textit{Accuracy}) se interpreta como la razón entre las predicciones correctas ($TP + TN$) y la cantidad total de instancias que analizó el modelo. Se computa sobre los resultados generales del modelo y se define como:

\begin{equation}
  E = \frac{TP + TN}{\textit{Total de Ejemplos}}
\end{equation}

La métrica estándar para calificar este tipo de exámenes consiste en sumar tres puntos si la respuesta está correcta y -1 si es incorrecta.

\section{Entrenamiento}

En esta sección se detalla el proceso de entrenamiento de los modelos propuestos anteriormente. 

Dado que una instancia del conjunto original se convierte en varios ejemplos diferentes, una por cada posible respuesta y que solo una de las respuestas es correcta, el conjunto de datos resultante del procesamiento de texto es un conjunto desbalanceado. Por una instancia positiva pueden aparecer al menos 3 instancias negativas.

Un conjunto de datos desequilibrado es el problema en el que los datos que pertenecen a una clase son significativamente más altos o más bajos que los que pertenecen a otras clases, como es el caso. La mayoría de los algoritmos de clasificación ML/DL no están equipados para manejar clases desequilibradas y tienden a inclinarse hacia las clases mayoritarias.

Para enfrentar este problema se han implementado varias técnicas de remuestreo cuyo objetivo es equilibrar la cantidad de muestras en cada una de las clases. La idea más sencilla para balancear un conjunto de datos es añadiendo muestras de la clase minoritaria o eliminando de la clase mayoritaria, sin embargo, estás técnicas tienen riesgo de \textit{overfitting} y \textit{underfitting} respectivamente. En la práctica resultan más efectivas técnicas avanzadas como SMOTE (del inglés, \textit{Synthetic Minority Over-sampling Technique}) que crean datos sintéticos de la case minoritaria. Sin embargo, SMOTE no se dempeña bien en el ámbito de datos textuales por la alta dimensiónde de los vectores que se obtienen a partir de texto.

Teniendo en cuenta esto, se han implementado las siguientes técnicas de remuestreo:

\begin{itemize}
  \item \textit{Random Undersampling}: Este algoritmo consiste en eliminar del conjunto de datos transformados instancias negativas de manera aleatoria hasta igualar la cantidad de instancias positivas y negativas.
  \item \textit{Random oversampling}: Este proceso es muy similar al anterior desde el punto de vista de la aleatoriedad pero adiciona instancias positivas al \textit{dataset} hasta igualar la cantidad de instancias de cada etiqueta.
  \item \textit{Mixed oversampling}: El objetivo de esta técnica es reproducir el comportamiento de los algoritmos de generación sintética de datos. El concepto también es similar a \textit{Data Augmentation}, común en el procesamiento de imágenes, que implica la creación de nuevas instancias aplicando transformaciones (como rotar, trasladar, escalar, entre otras) las del conjunto de datos original. En este caso, para generar texto a partir de las oraciones originales se recurre a la traducción y al reemplazamiento por sinónimos. El algoritmo de traducción toma una oración y la traduce al idioma inglés, del inglés al alemán y luego, nuevamente al castellano. Se introduce un idioma intermedio para lograr una mayor diferencia entre la oración original y la resultante. Esto podría resultar contraproducente pues puede cambiar el sentido de la oración original, lo cual se verá en la evaluación de los modelos. Por otra parte, la otra técnica consiste en a partir de una oración obtener otra compuesta por las palabras más parecidas a cada una de las palabras de la oración original. Las palabras más similares a un témino dado se han determinado a partir del uso de sus \textit{word embeddings}. En este caso, se han utilizado \textit{embeddings} obtenidos aplicando el algoritmo Fasttext sobre el \textit{Spanish Billion Word Corpus}\footnote{http://crscardellino.github.io/SBWCE/} descargado de \cite{spanish-word-embeddings}. 
\end{itemize}

En las secciones posteriores se muestran los resultados de los modelos propuestos utilizando como entrenamiento las diferentes técnicas de remuestreo.

\section{Evaluación de los modelos}

Como se mencionó anteriormente, las preguntas del conjuntos de datos están separadas por categorías. El análisis descriptivo inicial arrojó que el vocabulario más frecuente variaba de acuerdo a la categoría. Por esta razón los modelos serán entrenados y evaludas tanto en el conjunto de datos completo, como en cada una de las categorías.

Además de los modelos de aprendizaje profundo detallados en el capítulo anterior, se implementa un modelo de regresión logística, por su simplicidad se puede utilizar como \textit{baseline} supervisado. 



\subsection{Evaluación general}

El conjunto de validación está compuesto solamente por 6 exámenes, uno de cada categoría, mientras que el conjunto de evaluación está confomado por 12, 2 de cada rama.


\begin{table}[!tb]
  \begin{center}
    \caption{Comparación general por cantidad de puntos TEST}
    \begin{tabular}{l|c|c|c}
      \textbf{Modelo} & \textbf{Entrenamiento} & \textbf{Media Puntos} & \textbf{Max Puntos}\\
      \hline
      Regresión Logística & Desbalanceado & - & - \\
      LSTM & Desbalanceado & 1 & 37 \\
      BiLSTM+Attn & Desbalanceado & 15 & 93 \\
      QA-LSTM & Desbalanceado & 15 & 74 \\
      QA-LSTM/CNN & Desbalanceado & 11 & 36 \\

      Regresión Logística & \textit{Oversampled} & -5 & 37 \\
      LSTM & \textit{Oversampled} & 2 & 56 \\
      BiLSTM+Attn & \textit{Oversampled} & -2 & 21 \\
      QA-LSTM & \textit{Oversampled} & 9 & 45 \\
      QA-LSTM/CNN & \textit{Oversampled} & 7 & 61 \\

      Regresión Logística & \textit{Mixed} & -9 & 21 \\
      LSTM & \textit{Mixed} & 11 & 39 \\
      BiLSTM+Attn & \textit{Mixed} & -3 & 40 \\
      QA-LSTM & \textit{Mixed} & 23 & 101 \\
      QA-LSTM/CNN & \textit{Mixed} & 4 & 49 \\

      QA-BERT & \textit{Undersampled} & 3 & 41 \\
      Sim-BERT & \textit{No} & -13 & 29 \\
    \end{tabular}
  \end{center}
  \label{comparison_points_general}
\end{table}


\begin{table}[!tb]
  \begin{center}
    \caption{Comparación general por cantidad de puntos TEST}
    \begin{tabular}{l|c|c|c}
      \textbf{Modelo} & \textbf{Entrenamiento} & \textbf{Media Exactitud} & \textbf{Max Exactitud}\\
      \hline
      Regresión Logística & Desbalanceado & - & - \\
      LSTM & Desbalanceado & 0,25 & 0,29 \\
      BiLSTM+Attn & Desbalanceado & 0,27 & 0,35 \\
      QA-LSTM & Desbalanceado & 0,26 & 0,33 \\
      QA-LSTM/CNN & Desbalanceado & 0,26 & 0,29 \\

      Regresión Logística & \textit{Oversampled} & 0.24 & 0,29 \\
      LSTM & \textit{Oversampled} & 0,25 & 0,31 \\
      BiLSTM+Attn & \textit{Oversampled} & 0,25 & 0,27 \\
      QA-LSTM & \textit{Oversampled} & 0,26 & 0,30 \\
      QA-LSTM/CNN & \textit{Oversampled} & 0,26 & 0,32 \\

      Regresión Logística & \textit{Mixed} & 0,24 & 0,27 \\
      LSTM & \textit{Mixed} & 0,26 & 0,29 \\
      BiLSTM+Attn & \textit{Mixed} & 0,25 & 0,29 \\
      QA-LSTM & \textit{Mixed} & 0,27 & 0,36 \\
      QA-LSTM/CNN & \textit{Mixed} & 0,25 & 0,30 \\

      QA-BERT & \textit{Undersampled} & 0,25 & 0,30 \\
      Sim-BERT & \textit{No} & 0,23 & 0,28 \\
    \end{tabular}
  \end{center}
  \label{comparison_acc_general}
\end{table}


\subsection{Evaluación por categorías}




\begin{table}[!tb]
  \begin{center}
    \caption{Comparación de los modelos por categorías por Puntos}
    \begin{tabular}{l|c|c|c|c|c|c}
      \textbf{Modelo} & \textbf{Biología} & \textbf{Enfermería} & \textbf{Farmacología} & \textbf{Medicina} & \textbf{Psicología} & \textbf{Química}\\
      \hline
      Regresión Logística & 1.132 & 452 & 1.132 & 452 & 452 & 1.132\\
      LSTM & 1.069 & 384 & 230 & 455 & 1.132 & 452 \\
      BiLSTM+Attn & 1.139 & 457 & 225 & 457 & 452 & 1.132 \\
      QA-LSTM & 1.149 & 455 & 231 & 463 & 231 & 463 \\
      QA-LSTM/CNN & 1.134 & 453 & 226 & 455 & 226 & 455 \\
      QA-BERT & 1.142 & 456 & 228 & 458 & 228 & 458 
    \end{tabular}
  \end{center}
  \label{comparison_points}
\end{table}


\begin{table}[!tb]
  \begin{center}
    \caption{Comparación de los modelos por categorías por Exactitud}
    \begin{tabular}{l|c|c|c|c|c|c}
      \textbf{Modelo} & \textbf{Biología} & \textbf{Enfermería} & \textbf{Farmacología} & \textbf{Medicina} & \textbf{Psicología} & \textbf{Química}\\
      \hline
      Regresión Logística & 1.132 & 452 & 1.132 & 452 & 452 & 1.132\\
      LSTM & 1.069 & 384 & 230 & 455 & 1.132 & 452 \\
      BiLSTM+Attn & 1.139 & 457 & 225 & 457 & 452 & 1.132 \\
      QA-LSTM & 1.149 & 455 & 231 & 463 & 231 & 463 \\
      QA-LSTM/CNN & 1.134 & 453 & 226 & 455 & 226 & 455 \\
      QA-BERT & 1.142 & 456 & 228 & 458 & 228 & 458 \\ 
    \end{tabular}
  \end{center}
  \label{comparison_accuracy}
\end{table}


Al filtrar el conjunto de datos original por categorías, la cantidad de muestras que 



\section{Análisis de los resultados}

Los algoritmos de clasificación, a diferencia de los algoritmos de regresión, durante el entrenamiento minimizan la función de pérdida seleccionada y no directamente la exactitud del modelo, aunque ambas estén relaciondas. De manera que el desempeño de un modelo, depende en gran medida de la función de pérdida seleccionada. 


Varias cosas que mejorar para la próxima:

- Otro enfoque
- Utilizar una función de pérdida que maximice la importancia de una respuesta correcta y penalice una incorrecta. Teniendo en cuenta ambos 
- Diseñar algoritmos híbridos que combinen las técnicas anteriormente empleadas bajo el enfoque de recuperación de información no supervisada o supervisada a distancia, con modelos del aprendizaje supervisado.



