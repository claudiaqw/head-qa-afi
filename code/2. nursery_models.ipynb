{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'nursery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  48.6619 valid loss 1.151 and accuracy 0.7433\n",
      "Epoch 1 train loss  48.8185 valid loss 1.151 and accuracy 0.7411\n",
      "Epoch 2 train loss  48.8107 valid loss 1.154 and accuracy 0.7377\n",
      "Epoch 3 train loss  48.8342 valid loss 1.266 and accuracy 0.7333\n",
      "Epoch 4 train loss  48.8600 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 5 train loss  48.8625 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 6 train loss  48.8601 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 7 train loss  48.8574 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 8 train loss  48.8426 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 9 train loss  48.8267 valid loss 0.921 and accuracy 0.7455\n",
      "Epoch 10 train loss  48.9786 valid loss 0.806 and accuracy 0.7455\n",
      "Epoch 11 train loss  48.8590 valid loss 1.266 and accuracy 0.7411\n",
      "Epoch 12 train loss  48.8388 valid loss 1.266 and accuracy 0.7377\n",
      "Epoch 13 train loss  48.8405 valid loss 1.239 and accuracy 0.7388\n",
      "Epoch 14 train loss  48.9744 valid loss 1.266 and accuracy 0.7455\n",
      "Epoch 15 train loss  48.8983 valid loss 1.266 and accuracy 0.7422\n",
      "Epoch 16 train loss  48.9135 valid loss 1.266 and accuracy 0.7388\n",
      "Epoch 17 train loss  49.0262 valid loss 1.266 and accuracy 0.7411\n",
      "Epoch 18 train loss  48.9084 valid loss 1.266 and accuracy 0.7400\n",
      "Epoch 19 train loss  48.8847 valid loss 1.266 and accuracy 0.7400\n",
      "Epoch 20 train loss  48.7673 valid loss 1.266 and accuracy 0.7321\n",
      "Epoch 21 train loss  38.8112 valid loss 2.532 and accuracy 0.3304\n",
      "Epoch 22 train loss  54.3584 valid loss 2.532 and accuracy 0.3661\n",
      "Epoch 23 train loss  55.3160 valid loss 1.656 and accuracy 0.5312\n",
      "Epoch 24 train loss  50.9384 valid loss 1.496 and accuracy 0.5993\n",
      "Epoch 25 train loss  51.6262 valid loss 1.381 and accuracy 0.6607\n",
      "Epoch 26 train loss  45.5449 valid loss 1.505 and accuracy 0.5971\n",
      "Epoch 27 train loss  50.3060 valid loss 1.381 and accuracy 0.6708\n",
      "Epoch 28 train loss  47.8649 valid loss 1.381 and accuracy 0.6708\n",
      "Epoch 29 train loss  47.8294 valid loss 1.381 and accuracy 0.6663\n"
     ]
    }
   ],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2043]), points: -42\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2571]), points: 13\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.6973 valid loss 0.027 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.7080 valid loss 0.026 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.6991 valid loss 0.025 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.6953 valid loss 0.025 and accuracy 0.2511\n",
      "Epoch 4 train loss  0.6920 valid loss 0.025 and accuracy 0.2511\n",
      "Epoch 5 train loss  0.6884 valid loss 0.025 and accuracy 0.2533\n",
      "Epoch 6 train loss  0.6829 valid loss 0.025 and accuracy 0.2667\n",
      "Epoch 7 train loss  0.6707 valid loss 0.025 and accuracy 0.2812\n",
      "Epoch 8 train loss  0.6512 valid loss 0.025 and accuracy 0.2991\n",
      "Epoch 9 train loss  0.6131 valid loss 0.024 and accuracy 0.3895\n",
      "Epoch 10 train loss  0.5656 valid loss 0.024 and accuracy 0.4799\n",
      "Epoch 11 train loss  0.5294 valid loss 0.024 and accuracy 0.5112\n",
      "Epoch 12 train loss  0.4841 valid loss 0.023 and accuracy 0.5681\n",
      "Epoch 13 train loss  0.4357 valid loss 0.023 and accuracy 0.5826\n",
      "Epoch 14 train loss  0.4068 valid loss 0.024 and accuracy 0.5882\n",
      "Epoch 15 train loss  0.3885 valid loss 0.024 and accuracy 0.5982\n",
      "Epoch 16 train loss  0.3713 valid loss 0.024 and accuracy 0.6083\n",
      "Epoch 17 train loss  0.3326 valid loss 0.026 and accuracy 0.5882\n",
      "Epoch 18 train loss  0.3260 valid loss 0.026 and accuracy 0.5804\n",
      "Epoch 19 train loss  0.3321 valid loss 0.027 and accuracy 0.5915\n",
      "Epoch 20 train loss  0.3051 valid loss 0.029 and accuracy 0.6172\n",
      "Epoch 21 train loss  0.2978 valid loss 0.029 and accuracy 0.5859\n",
      "Epoch 22 train loss  0.3015 valid loss 0.032 and accuracy 0.6094\n",
      "Epoch 23 train loss  0.2841 valid loss 0.032 and accuracy 0.5871\n",
      "Epoch 24 train loss  0.2795 valid loss 0.033 and accuracy 0.6094\n",
      "Epoch 25 train loss  0.2725 valid loss 0.035 and accuracy 0.6161\n",
      "Epoch 26 train loss  0.2668 valid loss 0.035 and accuracy 0.5938\n",
      "Epoch 27 train loss  0.2575 valid loss 0.037 and accuracy 0.5949\n",
      "Epoch 28 train loss  0.2555 valid loss 0.037 and accuracy 0.5915\n",
      "Epoch 29 train loss  0.2552 valid loss 0.036 and accuracy 0.5893\n",
      "Epoch 30 train loss  0.2578 valid loss 0.037 and accuracy 0.5748\n",
      "Epoch 31 train loss  0.2591 valid loss 0.036 and accuracy 0.5882\n",
      "Epoch 32 train loss  0.2400 valid loss 0.040 and accuracy 0.5837\n",
      "Epoch 33 train loss  0.2449 valid loss 0.040 and accuracy 0.5871\n",
      "Epoch 34 train loss  0.2390 valid loss 0.045 and accuracy 0.5893\n",
      "Epoch 35 train loss  0.2424 valid loss 0.044 and accuracy 0.5993\n",
      "Epoch 36 train loss  0.2394 valid loss 0.040 and accuracy 0.5792\n",
      "Epoch 37 train loss  0.2417 valid loss 0.041 and accuracy 0.5837\n",
      "Epoch 38 train loss  0.2377 valid loss 0.042 and accuracy 0.5826\n",
      "Epoch 39 train loss  0.2369 valid loss 0.044 and accuracy 0.5960\n",
      "Epoch 40 train loss  0.2314 valid loss 0.044 and accuracy 0.5670\n",
      "Epoch 41 train loss  0.2437 valid loss 0.047 and accuracy 0.5871\n",
      "Epoch 42 train loss  0.2337 valid loss 0.048 and accuracy 0.5848\n",
      "Epoch 43 train loss  0.2353 valid loss 0.047 and accuracy 0.5826\n",
      "Epoch 44 train loss  0.2258 valid loss 0.050 and accuracy 0.5982\n",
      "Epoch 45 train loss  0.2283 valid loss 0.047 and accuracy 0.5748\n",
      "Epoch 46 train loss  0.2306 valid loss 0.049 and accuracy 0.5725\n",
      "Epoch 47 train loss  0.2310 valid loss 0.047 and accuracy 0.5815\n",
      "Epoch 48 train loss  0.2280 valid loss 0.046 and accuracy 0.5837\n",
      "Epoch 49 train loss  0.2306 valid loss 0.049 and accuracy 0.5915\n"
     ]
    }
   ],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2217]), points: -26\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2747]), points: 45\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/basic_lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "described-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.3906 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 1 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 2 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 3 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 4 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 5 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 6 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 7 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 8 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 9 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 10 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 11 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 12 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 13 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 14 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 15 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 16 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 17 train loss  51.0638 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 18 train loss  51.0638 valid loss 2.472 and accuracy 0.2500\n",
      "Epoch 19 train loss  67.2165 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 20 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 21 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 22 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 23 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 24 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 25 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 26 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 27 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 28 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 29 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 30 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 31 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 32 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 33 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 34 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 35 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 36 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 37 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 38 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 39 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 40 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 41 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 42 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 43 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 44 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 45 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 46 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 47 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 48 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 49 train loss  48.9362 valid loss 0.921 and accuracy 0.7500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2087]), points: -38\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2440]), points: -11\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5015 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4944 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 2 train loss  0.4647 valid loss 0.003 and accuracy 0.7463\n",
      "Epoch 3 train loss  0.4109 valid loss 0.004 and accuracy 0.7213\n",
      "Epoch 4 train loss  0.3513 valid loss 0.004 and accuracy 0.7048\n",
      "Epoch 5 train loss  0.2835 valid loss 0.005 and accuracy 0.6818\n",
      "Epoch 6 train loss  0.2420 valid loss 0.006 and accuracy 0.6756\n",
      "Epoch 7 train loss  0.1999 valid loss 0.007 and accuracy 0.7050\n",
      "Epoch 8 train loss  0.1714 valid loss 0.007 and accuracy 0.7132\n",
      "Epoch 9 train loss  0.1326 valid loss 0.010 and accuracy 0.7132\n",
      "Epoch 10 train loss  0.1103 valid loss 0.008 and accuracy 0.6739\n",
      "Epoch 11 train loss  0.1076 valid loss 0.010 and accuracy 0.6912\n",
      "Epoch 12 train loss  0.0944 valid loss 0.009 and accuracy 0.6790\n",
      "Epoch 13 train loss  0.0749 valid loss 0.009 and accuracy 0.6835\n",
      "Epoch 14 train loss  0.0745 valid loss 0.010 and accuracy 0.6743\n",
      "Epoch 15 train loss  0.0750 valid loss 0.009 and accuracy 0.7094\n",
      "Epoch 16 train loss  0.0626 valid loss 0.011 and accuracy 0.7193\n",
      "Epoch 17 train loss  0.0583 valid loss 0.009 and accuracy 0.7004\n",
      "Epoch 18 train loss  0.0621 valid loss 0.011 and accuracy 0.7066\n",
      "Epoch 19 train loss  0.0517 valid loss 0.009 and accuracy 0.6963\n",
      "Epoch 20 train loss  0.0456 valid loss 0.010 and accuracy 0.7085\n",
      "Epoch 21 train loss  0.0421 valid loss 0.011 and accuracy 0.7169\n",
      "Epoch 22 train loss  0.0560 valid loss 0.011 and accuracy 0.7075\n",
      "Epoch 23 train loss  0.0510 valid loss 0.007 and accuracy 0.6695\n",
      "Epoch 24 train loss  0.0438 valid loss 0.011 and accuracy 0.7173\n",
      "Epoch 25 train loss  0.0460 valid loss 0.008 and accuracy 0.6961\n",
      "Epoch 26 train loss  0.0410 valid loss 0.007 and accuracy 0.6713\n",
      "Epoch 27 train loss  0.0391 valid loss 0.011 and accuracy 0.7101\n",
      "Epoch 28 train loss  0.0403 valid loss 0.008 and accuracy 0.6910\n",
      "Epoch 29 train loss  0.0409 valid loss 0.011 and accuracy 0.7129\n",
      "Epoch 30 train loss  0.0312 valid loss 0.012 and accuracy 0.6926\n",
      "Epoch 31 train loss  0.0328 valid loss 0.009 and accuracy 0.6987\n",
      "Epoch 32 train loss  0.0313 valid loss 0.010 and accuracy 0.6904\n",
      "Epoch 33 train loss  0.0389 valid loss 0.008 and accuracy 0.6926\n",
      "Epoch 34 train loss  0.0366 valid loss 0.011 and accuracy 0.6972\n",
      "Epoch 35 train loss  0.0279 valid loss 0.011 and accuracy 0.7153\n",
      "Epoch 36 train loss  0.0357 valid loss 0.012 and accuracy 0.7037\n",
      "Epoch 37 train loss  0.0366 valid loss 0.008 and accuracy 0.7037\n",
      "Epoch 38 train loss  0.0279 valid loss 0.012 and accuracy 0.6996\n",
      "Epoch 39 train loss  0.0255 valid loss 0.010 and accuracy 0.7097\n",
      "Epoch 40 train loss  0.0237 valid loss 0.008 and accuracy 0.6686\n",
      "Epoch 41 train loss  0.0309 valid loss 0.013 and accuracy 0.7193\n",
      "Epoch 42 train loss  0.0294 valid loss 0.010 and accuracy 0.7061\n",
      "Epoch 43 train loss  0.0261 valid loss 0.008 and accuracy 0.6941\n",
      "Epoch 44 train loss  0.0258 valid loss 0.012 and accuracy 0.7000\n",
      "Epoch 45 train loss  0.0336 valid loss 0.009 and accuracy 0.6998\n",
      "Epoch 46 train loss  0.0267 valid loss 0.009 and accuracy 0.6910\n",
      "Epoch 47 train loss  0.0195 valid loss 0.012 and accuracy 0.7033\n",
      "Epoch 48 train loss  0.0223 valid loss 0.009 and accuracy 0.6903\n",
      "Epoch 49 train loss  0.0249 valid loss 0.011 and accuracy 0.7097\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2478]), points: -2\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2681]), points: 33\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5017 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4945 valid loss 0.003 and accuracy 0.7502\n",
      "Epoch 2 train loss  0.4681 valid loss 0.003 and accuracy 0.7349\n",
      "Epoch 3 train loss  0.4263 valid loss 0.003 and accuracy 0.6965\n",
      "Epoch 4 train loss  0.3666 valid loss 0.004 and accuracy 0.6980\n",
      "Epoch 5 train loss  0.3041 valid loss 0.004 and accuracy 0.6985\n",
      "Epoch 6 train loss  0.2525 valid loss 0.004 and accuracy 0.6601\n",
      "Epoch 7 train loss  0.1999 valid loss 0.005 and accuracy 0.6188\n",
      "Epoch 8 train loss  0.1738 valid loss 0.006 and accuracy 0.6362\n",
      "Epoch 9 train loss  0.1419 valid loss 0.006 and accuracy 0.6733\n",
      "Epoch 10 train loss  0.1242 valid loss 0.009 and accuracy 0.7018\n",
      "Epoch 11 train loss  0.0903 valid loss 0.009 and accuracy 0.6956\n",
      "Epoch 12 train loss  0.0896 valid loss 0.009 and accuracy 0.7169\n",
      "Epoch 13 train loss  0.0846 valid loss 0.008 and accuracy 0.6886\n",
      "Epoch 14 train loss  0.0671 valid loss 0.008 and accuracy 0.6811\n",
      "Epoch 15 train loss  0.0644 valid loss 0.009 and accuracy 0.6928\n",
      "Epoch 16 train loss  0.0692 valid loss 0.007 and accuracy 0.7081\n",
      "Epoch 17 train loss  0.0625 valid loss 0.010 and accuracy 0.6952\n",
      "Epoch 18 train loss  0.0506 valid loss 0.008 and accuracy 0.6985\n",
      "Epoch 19 train loss  0.0485 valid loss 0.011 and accuracy 0.6831\n",
      "Epoch 20 train loss  0.0519 valid loss 0.008 and accuracy 0.6884\n",
      "Epoch 21 train loss  0.0519 valid loss 0.010 and accuracy 0.6989\n",
      "Epoch 22 train loss  0.0500 valid loss 0.008 and accuracy 0.6664\n",
      "Epoch 23 train loss  0.0436 valid loss 0.011 and accuracy 0.6811\n",
      "Epoch 24 train loss  0.0489 valid loss 0.007 and accuracy 0.6993\n",
      "Epoch 25 train loss  0.0457 valid loss 0.009 and accuracy 0.6789\n",
      "Epoch 26 train loss  0.0407 valid loss 0.008 and accuracy 0.6822\n",
      "Epoch 27 train loss  0.0371 valid loss 0.008 and accuracy 0.6829\n",
      "Epoch 28 train loss  0.0363 valid loss 0.006 and accuracy 0.6801\n",
      "Epoch 29 train loss  0.0421 valid loss 0.006 and accuracy 0.6733\n",
      "Epoch 30 train loss  0.0398 valid loss 0.006 and accuracy 0.7204\n",
      "Epoch 31 train loss  0.0357 valid loss 0.008 and accuracy 0.6814\n",
      "Epoch 32 train loss  0.0351 valid loss 0.008 and accuracy 0.6844\n",
      "Epoch 33 train loss  0.0364 valid loss 0.011 and accuracy 0.7031\n",
      "Epoch 34 train loss  0.0287 valid loss 0.010 and accuracy 0.6869\n",
      "Epoch 35 train loss  0.0288 valid loss 0.013 and accuracy 0.7079\n",
      "Epoch 36 train loss  0.0312 valid loss 0.008 and accuracy 0.7024\n",
      "Epoch 37 train loss  0.0378 valid loss 0.007 and accuracy 0.7017\n",
      "Epoch 38 train loss  0.0441 valid loss 0.007 and accuracy 0.6983\n",
      "Epoch 39 train loss  0.0258 valid loss 0.009 and accuracy 0.6965\n",
      "Epoch 40 train loss  0.0322 valid loss 0.009 and accuracy 0.7055\n",
      "Epoch 41 train loss  0.0259 valid loss 0.011 and accuracy 0.7020\n",
      "Epoch 42 train loss  0.0295 valid loss 0.008 and accuracy 0.6831\n",
      "Epoch 43 train loss  0.0280 valid loss 0.009 and accuracy 0.6774\n",
      "Epoch 44 train loss  0.0254 valid loss 0.012 and accuracy 0.6994\n",
      "Epoch 45 train loss  0.0258 valid loss 0.010 and accuracy 0.6752\n",
      "Epoch 46 train loss  0.0280 valid loss 0.011 and accuracy 0.7050\n",
      "Epoch 47 train loss  0.0354 valid loss 0.007 and accuracy 0.6697\n",
      "Epoch 48 train loss  0.0254 valid loss 0.009 and accuracy 0.7031\n",
      "Epoch 49 train loss  0.0221 valid loss 0.008 and accuracy 0.6675\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2522]), points: 2\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2330]), points: -31\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_cnn_qa_sig_{CATEGORY}'\n",
    "torch.save(lstm_cnn_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
