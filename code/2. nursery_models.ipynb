{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'nursery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  47.7163 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 1 train loss  47.1762 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 2 train loss  47.2937 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 3 train loss  47.2867 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 4 train loss  47.2958 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 5 train loss  47.2825 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 6 train loss  47.2959 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 7 train loss  47.3773 valid loss 1.036 and accuracy 0.7489\n",
      "Epoch 8 train loss  47.4878 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 9 train loss  47.5163 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 10 train loss  47.5163 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 11 train loss  47.5164 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 12 train loss  47.5165 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 13 train loss  47.5165 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 14 train loss  47.5166 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 15 train loss  47.5167 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 16 train loss  47.5168 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 17 train loss  47.5168 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 18 train loss  47.5169 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 19 train loss  47.5170 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 20 train loss  47.5171 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 21 train loss  47.5172 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 22 train loss  47.5174 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 23 train loss  47.5175 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 24 train loss  47.5176 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 25 train loss  47.5178 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 26 train loss  47.5179 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 27 train loss  47.5180 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 28 train loss  47.5182 valid loss 1.036 and accuracy 0.7478\n",
      "Epoch 29 train loss  47.5184 valid loss 1.036 and accuracy 0.7478\n"
     ]
    }
   ],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2087]), points: -38\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2462]), points: -7\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  1.7144 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 1 train loss  1.7124 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 2 train loss  1.7114 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 3 train loss  1.7113 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 4 train loss  1.7106 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 5 train loss  1.7105 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 6 train loss  1.7087 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 7 train loss  1.7086 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 8 train loss  1.7072 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 9 train loss  1.7057 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 10 train loss  1.7028 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 11 train loss  1.7005 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 12 train loss  1.6972 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 13 train loss  1.6926 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 14 train loss  1.6867 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 15 train loss  1.6816 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 16 train loss  1.6713 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 17 train loss  1.6612 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 18 train loss  1.6538 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 19 train loss  1.6450 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 20 train loss  1.6393 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 21 train loss  1.6344 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 22 train loss  1.6259 valid loss 0.035 and accuracy 0.7500\n",
      "Epoch 23 train loss  1.6250 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 24 train loss  1.6195 valid loss 0.040 and accuracy 0.7500\n",
      "Epoch 25 train loss  1.6150 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 26 train loss  1.6136 valid loss 0.041 and accuracy 0.7500\n",
      "Epoch 27 train loss  1.6098 valid loss 0.040 and accuracy 0.7500\n",
      "Epoch 28 train loss  1.6070 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 29 train loss  1.6053 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 30 train loss  1.6042 valid loss 0.041 and accuracy 0.7500\n",
      "Epoch 31 train loss  1.6040 valid loss 0.040 and accuracy 0.7500\n",
      "Epoch 32 train loss  1.6017 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 33 train loss  1.6004 valid loss 0.045 and accuracy 0.7500\n",
      "Epoch 34 train loss  1.5989 valid loss 0.042 and accuracy 0.7500\n",
      "Epoch 35 train loss  1.5990 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 36 train loss  1.5993 valid loss 0.046 and accuracy 0.7500\n",
      "Epoch 37 train loss  1.5960 valid loss 0.048 and accuracy 0.7500\n",
      "Epoch 38 train loss  1.5950 valid loss 0.049 and accuracy 0.7500\n",
      "Epoch 39 train loss  1.5958 valid loss 0.045 and accuracy 0.7500\n",
      "Epoch 40 train loss  1.5935 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 41 train loss  1.5948 valid loss 0.043 and accuracy 0.7500\n",
      "Epoch 42 train loss  1.5938 valid loss 0.046 and accuracy 0.7500\n",
      "Epoch 43 train loss  1.5946 valid loss 0.053 and accuracy 0.7500\n",
      "Epoch 44 train loss  1.5938 valid loss 0.046 and accuracy 0.7500\n",
      "Epoch 45 train loss  1.5926 valid loss 0.054 and accuracy 0.7500\n",
      "Epoch 46 train loss  1.5916 valid loss 0.050 and accuracy 0.7500\n",
      "Epoch 47 train loss  1.5897 valid loss 0.057 and accuracy 0.7500\n",
      "Epoch 48 train loss  1.5919 valid loss 0.052 and accuracy 0.7500\n",
      "Epoch 49 train loss  1.5904 valid loss 0.040 and accuracy 0.7500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2217]), points: -26\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2637]), points: 25\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/basic_lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "described-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  1.7210 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 1 train loss  1.7147 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 2 train loss  1.7136 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 3 train loss  1.7141 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 4 train loss  1.7132 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 5 train loss  1.7130 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 6 train loss  1.7145 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 7 train loss  1.7129 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 8 train loss  1.7134 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 9 train loss  1.7126 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 10 train loss  1.7124 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 11 train loss  1.7119 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 12 train loss  1.7112 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 13 train loss  1.7113 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 14 train loss  1.7111 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 15 train loss  1.7098 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 16 train loss  1.7097 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 17 train loss  1.7085 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 18 train loss  1.7070 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 19 train loss  1.7063 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 20 train loss  1.7062 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 21 train loss  1.7040 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 22 train loss  1.7055 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 23 train loss  1.7010 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 24 train loss  1.7012 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 25 train loss  1.6963 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 26 train loss  1.6971 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 27 train loss  1.6991 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 28 train loss  1.6935 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 29 train loss  1.6960 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 30 train loss  1.6928 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 31 train loss  1.6889 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 32 train loss  1.6903 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 33 train loss  1.6865 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 34 train loss  1.6845 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 35 train loss  1.6820 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 36 train loss  1.6816 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 37 train loss  1.6809 valid loss 0.033 and accuracy 0.7500\n",
      "Epoch 38 train loss  1.6796 valid loss 0.035 and accuracy 0.7500\n",
      "Epoch 39 train loss  1.6773 valid loss 0.035 and accuracy 0.7500\n",
      "Epoch 40 train loss  1.6784 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 41 train loss  1.6772 valid loss 0.035 and accuracy 0.7500\n",
      "Epoch 42 train loss  1.6743 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 43 train loss  1.6729 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 44 train loss  1.6706 valid loss 0.035 and accuracy 0.7500\n",
      "Epoch 45 train loss  1.6691 valid loss 0.034 and accuracy 0.7500\n",
      "Epoch 46 train loss  1.6653 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 47 train loss  1.6660 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 48 train loss  1.6661 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 49 train loss  1.6642 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 50 train loss  1.6643 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 51 train loss  1.6667 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 52 train loss  1.6652 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 53 train loss  1.6621 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 54 train loss  1.6602 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 55 train loss  1.6585 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 56 train loss  1.6644 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 57 train loss  1.6610 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 58 train loss  1.6611 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 59 train loss  1.6557 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 60 train loss  1.6546 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 61 train loss  1.6574 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 62 train loss  1.6540 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 63 train loss  1.6532 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 64 train loss  1.6562 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 65 train loss  1.6549 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 66 train loss  1.6557 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 67 train loss  1.6515 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 68 train loss  1.6541 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 69 train loss  1.6510 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 70 train loss  1.6495 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 71 train loss  1.6478 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 72 train loss  1.6481 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 73 train loss  1.6483 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 74 train loss  1.6495 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 75 train loss  1.6499 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 76 train loss  1.6485 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 77 train loss  1.6497 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 78 train loss  1.6470 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 79 train loss  1.6478 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 80 train loss  1.6477 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 81 train loss  1.6501 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 82 train loss  1.6441 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 83 train loss  1.6453 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 84 train loss  1.6455 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 85 train loss  1.6471 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 86 train loss  1.6516 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 87 train loss  1.6432 valid loss 0.039 and accuracy 0.7500\n",
      "Epoch 88 train loss  1.6436 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 89 train loss  1.6434 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 90 train loss  1.6447 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 91 train loss  1.6403 valid loss 0.040 and accuracy 0.7500\n",
      "Epoch 92 train loss  1.6407 valid loss 0.040 and accuracy 0.7500\n",
      "Epoch 93 train loss  1.6429 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 94 train loss  1.6435 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 95 train loss  1.6424 valid loss 0.036 and accuracy 0.7500\n",
      "Epoch 96 train loss  1.6390 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 97 train loss  1.6424 valid loss 0.037 and accuracy 0.7500\n",
      "Epoch 98 train loss  1.6426 valid loss 0.038 and accuracy 0.7500\n",
      "Epoch 99 train loss  1.6401 valid loss 0.040 and accuracy 0.7500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.2087]), points: -38\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2264]), points: -43\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.7189 valid loss 0.005 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.7130 valid loss 0.005 and accuracy 0.7500\n",
      "Epoch 2 train loss  0.6916 valid loss 0.005 and accuracy 0.7500\n",
      "Epoch 3 train loss  0.6468 valid loss 0.005 and accuracy 0.7500\n",
      "Epoch 4 train loss  0.6078 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 5 train loss  0.5801 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 6 train loss  0.5552 valid loss 0.007 and accuracy 0.7494\n",
      "Epoch 7 train loss  0.5307 valid loss 0.006 and accuracy 0.7489\n",
      "Epoch 8 train loss  0.5199 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 9 train loss  0.5048 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 10 train loss  0.4978 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 11 train loss  0.4840 valid loss 0.006 and accuracy 0.7476\n",
      "Epoch 12 train loss  0.4814 valid loss 0.007 and accuracy 0.7491\n",
      "Epoch 13 train loss  0.4781 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 14 train loss  0.4716 valid loss 0.006 and accuracy 0.7483\n",
      "Epoch 15 train loss  0.4667 valid loss 0.006 and accuracy 0.7498\n",
      "Epoch 16 train loss  0.4606 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 17 train loss  0.4582 valid loss 0.006 and accuracy 0.7478\n",
      "Epoch 18 train loss  0.4577 valid loss 0.006 and accuracy 0.7480\n",
      "Epoch 19 train loss  0.4562 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 20 train loss  0.4494 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 21 train loss  0.4498 valid loss 0.006 and accuracy 0.7478\n",
      "Epoch 22 train loss  0.4485 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 23 train loss  0.4462 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 24 train loss  0.4417 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 25 train loss  0.4423 valid loss 0.005 and accuracy 0.7485\n",
      "Epoch 26 train loss  0.4411 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 27 train loss  0.4402 valid loss 0.006 and accuracy 0.7498\n",
      "Epoch 28 train loss  0.4382 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 29 train loss  0.4360 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 30 train loss  0.4346 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 31 train loss  0.4344 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 32 train loss  0.4350 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 33 train loss  0.4358 valid loss 0.006 and accuracy 0.7483\n",
      "Epoch 34 train loss  0.4328 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 35 train loss  0.4318 valid loss 0.006 and accuracy 0.7476\n",
      "Epoch 36 train loss  0.4303 valid loss 0.006 and accuracy 0.7489\n",
      "Epoch 37 train loss  0.4288 valid loss 0.005 and accuracy 0.7478\n",
      "Epoch 38 train loss  0.4288 valid loss 0.006 and accuracy 0.7489\n",
      "Epoch 39 train loss  0.4259 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 40 train loss  0.4261 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 41 train loss  0.4268 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 42 train loss  0.4241 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 43 train loss  0.4242 valid loss 0.005 and accuracy 0.7476\n",
      "Epoch 44 train loss  0.4236 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 45 train loss  0.4231 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 46 train loss  0.4222 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 47 train loss  0.4226 valid loss 0.006 and accuracy 0.7489\n",
      "Epoch 48 train loss  0.4213 valid loss 0.006 and accuracy 0.7489\n",
      "Epoch 49 train loss  0.4214 valid loss 0.006 and accuracy 0.7476\n",
      "Epoch 50 train loss  0.4208 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 51 train loss  0.4214 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 52 train loss  0.4218 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 53 train loss  0.4200 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 54 train loss  0.4219 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 55 train loss  0.4196 valid loss 0.006 and accuracy 0.7498\n",
      "Epoch 56 train loss  0.4178 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 57 train loss  0.4187 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 58 train loss  0.4184 valid loss 0.006 and accuracy 0.7483\n",
      "Epoch 59 train loss  0.4164 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 60 train loss  0.4167 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 61 train loss  0.4159 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 62 train loss  0.4155 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 63 train loss  0.4172 valid loss 0.005 and accuracy 0.7493\n",
      "Epoch 64 train loss  0.4138 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 65 train loss  0.4146 valid loss 0.006 and accuracy 0.7482\n",
      "Epoch 66 train loss  0.4141 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 67 train loss  0.4150 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 68 train loss  0.4138 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 69 train loss  0.4125 valid loss 0.006 and accuracy 0.7483\n",
      "Epoch 70 train loss  0.4126 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 71 train loss  0.4129 valid loss 0.006 and accuracy 0.7483\n",
      "Epoch 72 train loss  0.4125 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 73 train loss  0.4122 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 74 train loss  0.4104 valid loss 0.006 and accuracy 0.7498\n",
      "Epoch 75 train loss  0.4112 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 76 train loss  0.4112 valid loss 0.005 and accuracy 0.7502\n",
      "Epoch 77 train loss  0.4127 valid loss 0.005 and accuracy 0.7491\n",
      "Epoch 78 train loss  0.4106 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 79 train loss  0.4106 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 80 train loss  0.4104 valid loss 0.006 and accuracy 0.7493\n",
      "Epoch 81 train loss  0.4101 valid loss 0.006 and accuracy 0.7494\n",
      "Epoch 82 train loss  0.4108 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 83 train loss  0.4107 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 84 train loss  0.4109 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 85 train loss  0.4086 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 86 train loss  0.4082 valid loss 0.006 and accuracy 0.7487\n",
      "Epoch 87 train loss  0.4100 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 88 train loss  0.4078 valid loss 0.006 and accuracy 0.7480\n",
      "Epoch 89 train loss  0.4093 valid loss 0.006 and accuracy 0.7500\n",
      "Epoch 90 train loss  0.4073 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 91 train loss  0.4101 valid loss 0.006 and accuracy 0.7500\n",
      "Epoch 92 train loss  0.4085 valid loss 0.006 and accuracy 0.7502\n",
      "Epoch 93 train loss  0.4078 valid loss 0.006 and accuracy 0.7500\n",
      "Epoch 94 train loss  0.4083 valid loss 0.006 and accuracy 0.7491\n",
      "Epoch 95 train loss  0.4083 valid loss 0.006 and accuracy 0.7485\n",
      "Epoch 96 train loss  0.4067 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 97 train loss  0.4077 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 98 train loss  0.4079 valid loss 0.006 and accuracy 0.7496\n",
      "Epoch 99 train loss  0.4053 valid loss 0.006 and accuracy 0.7496\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: nursery\n",
      "accuracy: tensor([0.1913]), points: -54\n",
      "----------\n",
      "TEST Dominio: nursery\n",
      "accuracy: tensor([0.2615]), points: 21\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9d2246c7489a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n\u001b[0m\u001b[0;32m      2\u001b[0m                pretrained_embeddings=embedding_matrix)\n\u001b[0;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_cnn_qa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mds\\TFM\\head-qa-afi\\code\\ir_models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab_size, hidden_size, x_size, n_classes, embedding_size, padding_idx, pretrained_embeddings)\u001b[0m\n\u001b[0;32m     48\u001b[0m     def __init__(self, vocab_size, hidden_size, x_size, n_classes, embedding_size=300,\n\u001b[0;32m     49\u001b[0m                  padding_idx=0, pretrained_embeddings=None): \n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM_CNN_QA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_cnn_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
