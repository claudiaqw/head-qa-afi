{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir, evaluate_better\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'medicine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "mixed_training = load_dataset_from_pickle('../data/mixed_oversampling_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(mixed_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  42.5911 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 1 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 2 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 3 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 4 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 5 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 6 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 7 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 8 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 9 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 10 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 11 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 12 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 13 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 14 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 15 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 16 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 17 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 18 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 19 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 20 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 21 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 22 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 23 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 24 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 25 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 26 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 27 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 28 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 29 train loss  42.5189 valid loss 0.921 and accuracy 0.7478\n"
     ]
    }
   ],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: medicine\n",
      "accuracy: tensor([0.7489]), points: 461\n",
      "----------\n",
      "TEST Dominio: medicine\n",
      "accuracy: tensor([0.7559]), points: 937\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models_v2/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.6680 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.7053 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 2 train loss  0.6950 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 3 train loss  0.6910 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 4 train loss  0.6896 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 5 train loss  0.6867 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 6 train loss  0.6844 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 7 train loss  0.6804 valid loss 0.024 and accuracy 0.7500\n",
      "Epoch 8 train loss  0.6749 valid loss 0.024 and accuracy 0.7489\n",
      "Epoch 9 train loss  0.6679 valid loss 0.024 and accuracy 0.7444\n",
      "Epoch 10 train loss  0.6602 valid loss 0.024 and accuracy 0.7388\n",
      "Epoch 11 train loss  0.6364 valid loss 0.024 and accuracy 0.7243\n",
      "Epoch 12 train loss  0.6113 valid loss 0.025 and accuracy 0.6853\n",
      "Epoch 13 train loss  0.5835 valid loss 0.026 and accuracy 0.6685\n",
      "Epoch 14 train loss  0.5496 valid loss 0.026 and accuracy 0.6440\n",
      "Epoch 15 train loss  0.5124 valid loss 0.027 and accuracy 0.6250\n",
      "Epoch 16 train loss  0.4750 valid loss 0.027 and accuracy 0.6038\n",
      "Epoch 17 train loss  0.4605 valid loss 0.028 and accuracy 0.6060\n",
      "Epoch 18 train loss  0.4396 valid loss 0.030 and accuracy 0.6004\n",
      "Epoch 19 train loss  0.4028 valid loss 0.033 and accuracy 0.5826\n",
      "Epoch 20 train loss  0.3987 valid loss 0.031 and accuracy 0.5926\n",
      "Epoch 21 train loss  0.3801 valid loss 0.034 and accuracy 0.5804\n",
      "Epoch 22 train loss  0.3596 valid loss 0.038 and accuracy 0.5859\n",
      "Epoch 23 train loss  0.3542 valid loss 0.037 and accuracy 0.5848\n",
      "Epoch 24 train loss  0.3441 valid loss 0.033 and accuracy 0.5848\n",
      "Epoch 25 train loss  0.3294 valid loss 0.038 and accuracy 0.5781\n",
      "Epoch 26 train loss  0.3253 valid loss 0.039 and accuracy 0.5826\n",
      "Epoch 27 train loss  0.3261 valid loss 0.040 and accuracy 0.5658\n",
      "Epoch 28 train loss  0.3084 valid loss 0.041 and accuracy 0.5781\n",
      "Epoch 29 train loss  0.3090 valid loss 0.042 and accuracy 0.5725\n",
      "Epoch 30 train loss  0.2937 valid loss 0.040 and accuracy 0.5647\n",
      "Epoch 31 train loss  0.3005 valid loss 0.041 and accuracy 0.5725\n",
      "Epoch 32 train loss  0.2882 valid loss 0.043 and accuracy 0.5714\n",
      "Epoch 33 train loss  0.2853 valid loss 0.042 and accuracy 0.5815\n",
      "Epoch 34 train loss  0.2870 valid loss 0.042 and accuracy 0.5792\n",
      "Epoch 35 train loss  0.2843 valid loss 0.043 and accuracy 0.5703\n",
      "Epoch 36 train loss  0.2780 valid loss 0.045 and accuracy 0.5770\n",
      "Epoch 37 train loss  0.2766 valid loss 0.048 and accuracy 0.5871\n",
      "Epoch 38 train loss  0.2692 valid loss 0.047 and accuracy 0.5703\n",
      "Epoch 39 train loss  0.2677 valid loss 0.046 and accuracy 0.5837\n",
      "Epoch 40 train loss  0.2710 valid loss 0.045 and accuracy 0.5904\n",
      "Epoch 41 train loss  0.2658 valid loss 0.047 and accuracy 0.5636\n",
      "Epoch 42 train loss  0.2661 valid loss 0.045 and accuracy 0.5480\n",
      "Epoch 43 train loss  0.2677 valid loss 0.040 and accuracy 0.6083\n",
      "Epoch 44 train loss  0.2647 valid loss 0.043 and accuracy 0.5871\n",
      "Epoch 45 train loss  0.2571 valid loss 0.042 and accuracy 0.5960\n",
      "Epoch 46 train loss  0.2577 valid loss 0.044 and accuracy 0.5915\n",
      "Epoch 47 train loss  0.2532 valid loss 0.043 and accuracy 0.6038\n",
      "Epoch 48 train loss  0.2577 valid loss 0.047 and accuracy 0.5982\n",
      "Epoch 49 train loss  0.2499 valid loss 0.049 and accuracy 0.5871\n"
     ]
    }
   ],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: medicine\n",
      "accuracy: tensor([0.5584]), points: 285\n",
      "----------\n",
      "TEST Dominio: medicine\n",
      "accuracy: tensor([0.6026]), points: 653\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models_v2/lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "described-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.4419 valid loss 1.022 and accuracy 0.2500\n",
      "Epoch 1 train loss  1.3515 valid loss 0.715 and accuracy 0.2500\n",
      "Epoch 2 train loss  1.4661 valid loss 0.412 and accuracy 0.2500\n",
      "Epoch 3 train loss  1.5565 valid loss 0.347 and accuracy 0.2500\n",
      "Epoch 4 train loss  1.2589 valid loss 0.426 and accuracy 0.2500\n",
      "Epoch 5 train loss  1.2791 valid loss 0.658 and accuracy 0.2500\n",
      "Epoch 6 train loss  1.7317 valid loss 0.247 and accuracy 0.2500\n",
      "Epoch 7 train loss  0.8928 valid loss 0.028 and accuracy 0.4944\n",
      "Epoch 8 train loss  0.5455 valid loss 0.398 and accuracy 0.2500\n",
      "Epoch 9 train loss  1.2190 valid loss 0.197 and accuracy 0.2500\n",
      "Epoch 10 train loss  0.7375 valid loss 0.517 and accuracy 0.2500\n",
      "Epoch 11 train loss  1.2416 valid loss 0.043 and accuracy 0.3471\n",
      "Epoch 12 train loss  0.6681 valid loss 0.550 and accuracy 0.2500\n",
      "Epoch 13 train loss  1.2698 valid loss 0.107 and accuracy 0.2556\n",
      "Epoch 14 train loss  0.6219 valid loss 0.360 and accuracy 0.2500\n",
      "Epoch 15 train loss  1.6044 valid loss 0.384 and accuracy 0.2500\n",
      "Epoch 16 train loss  0.8904 valid loss 0.035 and accuracy 0.4252\n",
      "Epoch 17 train loss  0.6637 valid loss 0.096 and accuracy 0.2567\n",
      "Epoch 18 train loss  0.5985 valid loss 0.657 and accuracy 0.2500\n",
      "Epoch 19 train loss  1.2155 valid loss 0.044 and accuracy 0.3627\n",
      "Epoch 20 train loss  0.6205 valid loss 0.421 and accuracy 0.2500\n",
      "Epoch 21 train loss  1.1636 valid loss 0.395 and accuracy 0.2500\n",
      "Epoch 22 train loss  1.9369 valid loss 0.531 and accuracy 0.2500\n",
      "Epoch 23 train loss  1.2273 valid loss 0.247 and accuracy 0.2500\n",
      "Epoch 24 train loss  0.9260 valid loss 0.584 and accuracy 0.2500\n",
      "Epoch 25 train loss  1.5743 valid loss 0.665 and accuracy 0.2500\n",
      "Epoch 26 train loss  1.3411 valid loss 0.410 and accuracy 0.2500\n",
      "Epoch 27 train loss  1.0070 valid loss 0.401 and accuracy 0.2500\n",
      "Epoch 28 train loss  0.9367 valid loss 0.444 and accuracy 0.2500\n",
      "Epoch 29 train loss  1.0763 valid loss 0.453 and accuracy 0.2500\n",
      "Epoch 30 train loss  1.0274 valid loss 0.338 and accuracy 0.2567\n",
      "Epoch 31 train loss  0.8841 valid loss 0.258 and accuracy 0.2612\n",
      "Epoch 32 train loss  0.9403 valid loss 0.061 and accuracy 0.3839\n",
      "Epoch 33 train loss  0.6969 valid loss 0.467 and accuracy 0.2500\n",
      "Epoch 34 train loss  1.0372 valid loss 0.062 and accuracy 0.3862\n",
      "Epoch 35 train loss  0.7865 valid loss 0.565 and accuracy 0.2500\n",
      "Epoch 36 train loss  1.3792 valid loss 0.417 and accuracy 0.2500\n",
      "Epoch 37 train loss  0.8307 valid loss 0.670 and accuracy 0.2500\n",
      "Epoch 38 train loss  1.9174 valid loss 0.708 and accuracy 0.2500\n",
      "Epoch 39 train loss  1.3850 valid loss 0.801 and accuracy 0.2500\n",
      "Epoch 40 train loss  1.3213 valid loss 0.376 and accuracy 0.2589\n",
      "Epoch 41 train loss  1.2254 valid loss 0.360 and accuracy 0.2645\n",
      "Epoch 42 train loss  0.8883 valid loss 0.590 and accuracy 0.2500\n",
      "Epoch 43 train loss  1.1825 valid loss 0.357 and accuracy 0.2522\n",
      "Epoch 44 train loss  0.7594 valid loss 0.120 and accuracy 0.3147\n",
      "Epoch 45 train loss  1.1295 valid loss 0.541 and accuracy 0.2500\n",
      "Epoch 46 train loss  1.1230 valid loss 0.318 and accuracy 0.2533\n",
      "Epoch 47 train loss  0.7785 valid loss 0.246 and accuracy 0.2712\n",
      "Epoch 48 train loss  0.9203 valid loss 0.239 and accuracy 0.2768\n",
      "Epoch 49 train loss  0.8835 valid loss 0.572 and accuracy 0.2500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: medicine\n",
      "accuracy: tensor([0.5758]), points: 301\n",
      "----------\n",
      "TEST Dominio: medicine\n",
      "accuracy: tensor([0.5983]), points: 645\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models_v2/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "mixed_training_ir = load_dataset_from_pickle('../data/mixed_oversampling_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(mixed_training_ir, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.4577 valid loss 0.178 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.8042 valid loss 0.087 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.7410 valid loss 0.054 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.7714 valid loss 0.028 and accuracy 0.7500\n",
      "Epoch 4 train loss  0.7098 valid loss 0.028 and accuracy 0.7500\n",
      "Epoch 5 train loss  0.7119 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 6 train loss  0.7036 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 7 train loss  0.7092 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 8 train loss  0.7135 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 9 train loss  0.7121 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 10 train loss  0.7146 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 11 train loss  0.7173 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 12 train loss  0.7091 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 13 train loss  0.7131 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 14 train loss  0.7111 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 15 train loss  0.7080 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 16 train loss  0.7018 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 17 train loss  0.6997 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 18 train loss  0.6891 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 19 train loss  0.7107 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 20 train loss  0.6987 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 21 train loss  0.6960 valid loss 0.027 and accuracy 0.7310\n",
      "Epoch 22 train loss  0.6903 valid loss 0.027 and accuracy 0.7076\n",
      "Epoch 23 train loss  0.6647 valid loss 0.034 and accuracy 0.3549\n",
      "Epoch 24 train loss  0.6593 valid loss 0.030 and accuracy 0.5368\n",
      "Epoch 25 train loss  0.6312 valid loss 0.031 and accuracy 0.4676\n",
      "Epoch 26 train loss  0.6104 valid loss 0.031 and accuracy 0.4788\n",
      "Epoch 27 train loss  0.5735 valid loss 0.033 and accuracy 0.4643\n",
      "Epoch 28 train loss  0.5367 valid loss 0.035 and accuracy 0.4342\n",
      "Epoch 29 train loss  0.4878 valid loss 0.041 and accuracy 0.3828\n",
      "Epoch 30 train loss  0.4466 valid loss 0.043 and accuracy 0.4141\n",
      "Epoch 31 train loss  0.3696 valid loss 0.052 and accuracy 0.4219\n",
      "Epoch 32 train loss  0.2961 valid loss 0.073 and accuracy 0.3750\n",
      "Epoch 33 train loss  0.2602 valid loss 0.076 and accuracy 0.3873\n",
      "Epoch 34 train loss  0.2059 valid loss 0.069 and accuracy 0.4609\n",
      "Epoch 35 train loss  0.1599 valid loss 0.058 and accuracy 0.5011\n",
      "Epoch 36 train loss  0.1441 valid loss 0.069 and accuracy 0.5067\n",
      "Epoch 37 train loss  0.1223 valid loss 0.057 and accuracy 0.5324\n",
      "Epoch 38 train loss  0.0957 valid loss 0.059 and accuracy 0.5357\n",
      "Epoch 39 train loss  0.0841 valid loss 0.044 and accuracy 0.5926\n",
      "Epoch 40 train loss  0.0652 valid loss 0.051 and accuracy 0.5770\n",
      "Epoch 41 train loss  0.0531 valid loss 0.048 and accuracy 0.5993\n",
      "Epoch 42 train loss  0.0443 valid loss 0.047 and accuracy 0.6060\n",
      "Epoch 43 train loss  0.0400 valid loss 0.044 and accuracy 0.6038\n",
      "Epoch 44 train loss  0.0289 valid loss 0.052 and accuracy 0.5893\n",
      "Epoch 45 train loss  0.0211 valid loss 0.062 and accuracy 0.5580\n",
      "Epoch 46 train loss  0.0206 valid loss 0.067 and accuracy 0.5714\n",
      "Epoch 47 train loss  0.0121 valid loss 0.057 and accuracy 0.5781\n",
      "Epoch 48 train loss  0.0109 valid loss 0.066 and accuracy 0.5759\n",
      "Epoch 49 train loss  0.0112 valid loss 0.057 and accuracy 0.5871\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: medicine\n",
      "accuracy: tensor([0.2641]), points: 13\n",
      "----------\n",
      "TEST Dominio: medicine\n",
      "accuracy: tensor([0.3002]), points: 93\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models_v2/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.4405 valid loss 0.204 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.8792 valid loss 0.065 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.7152 valid loss 0.055 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.7579 valid loss 0.032 and accuracy 0.3806\n",
      "Epoch 4 train loss  0.7071 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 5 train loss  0.6977 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 6 train loss  0.6966 valid loss 0.027 and accuracy 0.7500\n",
      "Epoch 7 train loss  0.6941 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 8 train loss  0.7020 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 9 train loss  0.7075 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 10 train loss  0.7085 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 11 train loss  0.7026 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 12 train loss  0.6977 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 13 train loss  0.6952 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 14 train loss  0.6965 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 15 train loss  0.7024 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 16 train loss  0.7019 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 17 train loss  0.6993 valid loss 0.026 and accuracy 0.7500\n",
      "Epoch 18 train loss  0.7005 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 19 train loss  0.6777 valid loss 0.028 and accuracy 0.7321\n",
      "Epoch 20 train loss  0.7120 valid loss 0.025 and accuracy 0.7500\n",
      "Epoch 21 train loss  0.6758 valid loss 0.028 and accuracy 0.7109\n",
      "Epoch 22 train loss  0.6825 valid loss 0.028 and accuracy 0.6886\n",
      "Epoch 23 train loss  0.6693 valid loss 0.028 and accuracy 0.6752\n",
      "Epoch 24 train loss  0.6069 valid loss 0.041 and accuracy 0.3326\n",
      "Epoch 25 train loss  0.6362 valid loss 0.028 and accuracy 0.6049\n",
      "Epoch 26 train loss  0.5642 valid loss 0.033 and accuracy 0.4420\n",
      "Epoch 27 train loss  0.5437 valid loss 0.034 and accuracy 0.4487\n",
      "Epoch 28 train loss  0.5031 valid loss 0.038 and accuracy 0.4632\n",
      "Epoch 29 train loss  0.4394 valid loss 0.052 and accuracy 0.3549\n",
      "Epoch 30 train loss  0.4012 valid loss 0.052 and accuracy 0.3504\n",
      "Epoch 31 train loss  0.3584 valid loss 0.054 and accuracy 0.3839\n",
      "Epoch 32 train loss  0.3051 valid loss 0.059 and accuracy 0.4074\n",
      "Epoch 33 train loss  0.2668 valid loss 0.056 and accuracy 0.4051\n",
      "Epoch 34 train loss  0.2388 valid loss 0.067 and accuracy 0.4230\n",
      "Epoch 35 train loss  0.1898 valid loss 0.063 and accuracy 0.5045\n",
      "Epoch 36 train loss  0.1568 valid loss 0.063 and accuracy 0.4978\n",
      "Epoch 37 train loss  0.1580 valid loss 0.069 and accuracy 0.4799\n",
      "Epoch 38 train loss  0.1289 valid loss 0.059 and accuracy 0.4955\n",
      "Epoch 39 train loss  0.1060 valid loss 0.065 and accuracy 0.5446\n",
      "Epoch 40 train loss  0.0956 valid loss 0.068 and accuracy 0.5815\n",
      "Epoch 41 train loss  0.0525 valid loss 0.075 and accuracy 0.6027\n",
      "Epoch 42 train loss  0.0422 valid loss 0.084 and accuracy 0.5904\n",
      "Epoch 43 train loss  0.0364 valid loss 0.086 and accuracy 0.6016\n",
      "Epoch 44 train loss  0.0302 valid loss 0.198 and accuracy 0.5547\n",
      "Epoch 45 train loss  0.0234 valid loss 0.102 and accuracy 0.5536\n",
      "Epoch 46 train loss  0.0237 valid loss 0.202 and accuracy 0.5614\n",
      "Epoch 47 train loss  0.0201 valid loss 0.199 and accuracy 0.5759\n",
      "Epoch 48 train loss  0.0148 valid loss 0.209 and accuracy 0.5647\n",
      "Epoch 49 train loss  0.0093 valid loss 0.211 and accuracy 0.5748\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: medicine\n",
      "accuracy: tensor([0.2727]), points: 21\n",
      "----------\n",
      "TEST Dominio: medicine\n",
      "accuracy: tensor([0.2873]), points: 69\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models_v2/lstm_cnn_qa_{CATEGORY}'\n",
    "torch.save(lstm_cnn_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-somalia",
   "metadata": {},
   "source": [
    "### Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "portable-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\mds\\TFM\\head-qa-afi\\code/trained_models_v2/logistic_regressor_medicine\n",
      "DEV\n",
      "Accuracy media 0.74891776\n",
      "Puntos media 461.0\n",
      "[tensor(0.7489)]\n",
      "[461]\n",
      "---------\n",
      "TEST\n",
      "Accuracy media 0.75594306\n",
      "Puntos media 468.5\n",
      "[tensor(0.7543), tensor(0.7576)]\n",
      "[468, 469]\n",
      "---------\n",
      "\n",
      "DEV\n",
      "Accuracy media 0.5584416\n",
      "Puntos media 285.0\n",
      "[tensor(0.5584)]\n",
      "[285]\n",
      "---------\n",
      "TEST\n",
      "Accuracy media 0.60252464\n",
      "Puntos media 326.5\n",
      "[tensor(0.6336), tensor(0.5714)]\n",
      "[356, 297]\n",
      "---------\n",
      "\n",
      "DEV\n",
      "Accuracy media 0.57575756\n",
      "Puntos media 301.0\n",
      "[tensor(0.5758)]\n",
      "[301]\n",
      "---------\n",
      "TEST\n",
      "Accuracy media 0.59827024\n",
      "Puntos media 322.5\n",
      "[tensor(0.5991), tensor(0.5974)]\n",
      "[324, 321]\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "\n",
    "models = [logistic_regressor, lstm, bilstm]\n",
    "paths = [os.getcwd() + f'/trained_models_v2/logistic_regressor_{CATEGORY}', \n",
    "         os.getcwd() + f'/trained_models_v2/lstm_{CATEGORY}',         \n",
    "         os.getcwd() + f'/trained_models_v2/bilstm_{CATEGORY}']\n",
    "\n",
    "print(paths[0])\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(torch.load(paths[i]))\n",
    "    model.eval()\n",
    "    acc, points, acc_list, points_list = evaluate_better(model, dev_categ, trainset.encode, evaluator)\n",
    "    print('DEV')\n",
    "    print('Accuracy media', acc)\n",
    "    print('Puntos media', points)\n",
    "    print(acc_list)\n",
    "    print(points_list)\n",
    "    print('---------')\n",
    "    acc, points, acc_list, points_list = evaluate_better(model, test_categ, trainset.encode, evaluator)\n",
    "    print('TEST')\n",
    "    print('Accuracy media', acc)\n",
    "    print('Puntos media', points)\n",
    "    print(acc_list)\n",
    "    print(points_list)\n",
    "    print('---------')\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "computational-screw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n",
      "Loading pretrained embeddings...\n",
      "DEV\n",
      "Accuracy media 0.26406926\n",
      "Puntos media 13.0\n",
      "[tensor(0.2641)]\n",
      "[13]\n",
      "---------\n",
      "TEST\n",
      "Accuracy media 0.30016607\n",
      "Puntos media 46.5\n",
      "[tensor(0.3233), tensor(0.2771)]\n",
      "[68, 25]\n",
      "---------\n",
      "\n",
      "DEV\n",
      "Accuracy media 0.27272728\n",
      "Puntos media 21.0\n",
      "[tensor(0.2727)]\n",
      "[21]\n",
      "---------\n",
      "TEST\n",
      "Accuracy media 0.28723502\n",
      "Puntos media 34.5\n",
      "[tensor(0.2974), tensor(0.2771)]\n",
      "[44, 25]\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "\n",
    "models = [lstm_qa, lstm_cnn_qa]\n",
    "\n",
    "paths = [os.getcwd() + f'/trained_models_v2/lstm_qa_{CATEGORY}',\n",
    "         os.getcwd() + f'/trained_models_v2/lstm_cnn_qa_{CATEGORY}'\n",
    "        ]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(torch.load(paths[i]))\n",
    "    model.eval()\n",
    "    acc, points, acc_list, points_list = evaluate_better(model, dev_categ, trainset.encode, evaluator_ir)\n",
    "    print('DEV')\n",
    "    print('Accuracy media', acc)\n",
    "    print('Puntos media', points)\n",
    "    print(acc_list)\n",
    "    print(points_list)\n",
    "    print('---------')\n",
    "    acc, points, acc_list, points_list = evaluate_better(model, test_categ, trainset.encode, evaluator_ir)\n",
    "    print('TEST')\n",
    "    print('Accuracy media', acc)\n",
    "    print('Puntos media', points)\n",
    "    print(acc_list)\n",
    "    print(points_list)\n",
    "    print('---------')\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
