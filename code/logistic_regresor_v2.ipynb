{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "democratic-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vocabulary, Vectorizer, HeadQA, clean_words, parse_dataset, save_dataset_to_pickle, load_dataset_from_pickle \n",
    "from utils_data import random_oversamplig, mixed_oversampling, similarity_instance, translate_instance, translate_instance_ir, similarity_instance_ir\n",
    "\n",
    "from training import train, validate, evaluate, evaluator, evaluate_better, get_optimizer\n",
    "\n",
    "from supervised_models import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "boring-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sonic-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adapted-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_instances = parse_dataset(training)\n",
    "# validation_instances = parse_dataset(validation)\n",
    "# testing_instances = parse_dataset(testing)\n",
    "\n",
    "# oversampled_training = random_oversamplig(training_instances)\n",
    "# mixed_oversampling_training = mixed_oversampling(training_instances, translate_instance, similarity_instance)\n",
    "\n",
    "# save_dataset_to_pickle('../data/training.pickle', training_instances)\n",
    "# save_dataset_to_pickle('../data/validation.pickle', validation_instances)\n",
    "# save_dataset_to_pickle('../data/testing.pickle', testing_instances)\n",
    "# save_dataset_to_pickle('../data/oversampled_training.pickle', oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "urban-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')\n",
    "mixed_training = load_dataset_from_pickle('../data/mixed_oversampling_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "biological-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Los potenciales postsinápticos excitadores:',\n",
       " 'answer': 'Son de tipo todo o nada.',\n",
       " 'tok_qtext': ['Los', 'potenciales', 'postsinápticos', 'excitadores', ':'],\n",
       " 'tok_atext': ['Son', 'de', 'tipo', 'todo', 'o', 'nada', '.'],\n",
       " 'label': 0,\n",
       " 'category': 'biology'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(mixed_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(model, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train(model, optimizer, train_dt, valid_dt, validate, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, validation, trainset.encode, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, testing, trainset.encode, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.getcwd() + '/trained_models/logistic_regressor'\n",
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_to_pickle('../data/train_results_lreg_sigmoid.pickle', training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = load_dataset_from_pickle('../data/train_results_lreg.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-living",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
