{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_BERT = 'dccuchile/bert-base-spanish-wwm-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_instances = parse_dataset(training)\n",
    "# validation_instances = parse_dataset(validation)\n",
    "# testing_instances = parse_dataset(testing)\n",
    "\n",
    "# oversampled_training = random_oversamplig(training_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BASE_BERT, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(x, seq_len=110, right_padding = False):\n",
    "    z = np.zeros(seq_len, dtype=np.int32)\n",
    "    n = min(seq_len, len(x))\n",
    "    if right_padding:\n",
    "        z[:n] = x[0:n]\n",
    "    else:\n",
    "        z[(seq_len - n):] = x[0:n]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_instances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ir(samples, tokenizer):\n",
    "    input_ids_0, input_ids_1, labels = [], [], []\n",
    "    for item in samples:\n",
    "        encoded_q = tokenizer.encode(item['question'], add_special_tokens = True)\n",
    "        encoded_a = tokenizer.encode(item['answer'], add_special_tokens = True)\n",
    "        padded_q = pad_seq(encoded_q, seq_len=30)\n",
    "        padded_a = pad_seq(encoded_a, seq_len=30)\n",
    "        input_ids_0.append(padded_q)\n",
    "        input_ids_1.append(padded_a)\n",
    "        labels.append(item['label'])\n",
    "        \n",
    "    attention_masks_0, attention_masks_1 = [], []\n",
    "    for sent in input_ids_0:  \n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks_0.append(att_mask)\n",
    "    \n",
    "    for sent in input_ids_1:  \n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks_1.append(att_mask)\n",
    "        \n",
    "    return input_ids_0, attention_masks_0, input_ids_1, attention_masks_1, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_0, train_masks_0, train_inputs_1, train_masks_1, train_labels = encode_ir(oversampled_training, tokenizer)\n",
    "valid_inputs_0, valid_masks_0, valid_inputs_1, valid_masks_1, valid_labels = encode_ir(validation_instances, tokenizer)\n",
    "test_inputs_0, test_masks_0, test_inputs_1, test_masks_1, test_labels = encode_ir(testing_instances, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_0 = torch.tensor(train_inputs_0)\n",
    "valid_inputs_0 = torch.tensor(valid_inputs_0)\n",
    "test_inputs_0 = torch.tensor(test_inputs_0)\n",
    "\n",
    "train_masks_0 = torch.tensor(train_masks_0)\n",
    "valid_masks_0 = torch.tensor(valid_masks_0)\n",
    "test_masks_0 = torch.tensor(test_masks_0)\n",
    "\n",
    "train_inputs_1 = torch.tensor(train_inputs_1)\n",
    "valid_inputs_1 = torch.tensor(valid_inputs_1)\n",
    "test_inputs_1 = torch.tensor(test_inputs_1)\n",
    "\n",
    "train_masks_1 = torch.tensor(train_masks_1)\n",
    "valid_masks_1 = torch.tensor(valid_masks_1)\n",
    "test_masks_1 = torch.tensor(test_masks_1)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "valid_labels = torch.tensor(valid_labels)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs_0, train_masks_0, train_inputs_1, train_masks_1, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "valid_data = TensorDataset(valid_inputs_0, valid_masks_0, valid_inputs_1, valid_masks_1, valid_labels)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs_0, test_masks_0, test_inputs_1, test_masks_1, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import spacy\n",
    "import pickle\n",
    "import collections\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_QA(torch.nn.Module):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels=1, pretrained_model='bert-base-uncased', seq_length=30):\n",
    "        super(BERT_QA, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model)\n",
    "        config = self.bert.config\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.cosine = nn.CosineSimilarity(dim=1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 256)\n",
    "        self.classifier_1 = nn.Linear(256, self.num_labels)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "    def forward(self, input_ids_0, attention_mask_0, input_ids_1, attention_mask_1, labels=None, output_hidden_states=True):\n",
    "        outputs_0 = self.bert(input_ids_0, attention_mask=attention_mask_0, output_hidden_states=output_hidden_states)\n",
    "        outputs_1 = self.bert(input_ids_1, attention_mask=attention_mask_1, output_hidden_states=output_hidden_states)\n",
    "        a = torch.cat(outputs_0[2][:4], dim=1)\n",
    "        b = torch.cat(outputs_1[2][:4], dim=1)\n",
    "        s = self.cosine(a, b)\n",
    "        x = self.classifier(s)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier_1(x)\n",
    "        return F.softmax(x, dim=0)\n",
    "\n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_QA(pretrained_model=BASE_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for batch in train_dataloader:    \n",
    "    print(len(batch))\n",
    "    b_input_ids_0, b_input_mask_0 = batch[0].long(), batch[1]\n",
    "    b_input_ids_1, b_input_mask_1 = batch[2].long(), batch[3]\n",
    "    b_labels = batch[4]\n",
    "#     model.zero_grad()\n",
    "    output = model(input_ids_0=b_input_ids_0, \n",
    "              attention_mask_0=b_input_mask_0, \n",
    "              input_ids_1=b_input_ids_1,\n",
    "              attention_mask_1=b_input_mask_1,\n",
    "              labels=b_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.round(preds, axis=0)\n",
    "    labels_flat = labels\n",
    "    print(pred_flat, labels_flat)\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, epochs):\n",
    "    import random\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # Store the average loss after each epoch so we can plot them.\n",
    "    loss_values = []\n",
    "    epochs_results = []\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            b_input_ids_0, b_input_mask_0 = batch[0].long(), batch[1]\n",
    "            b_input_ids_1, b_input_mask_1 = batch[2].long(), batch[3]\n",
    "            b_labels = batch[4]\n",
    "            model.zero_grad()\n",
    "            out = model(input_ids_0=b_input_ids_0, \n",
    "                      attention_mask_0=b_input_mask_0, \n",
    "                      input_ids_1=b_input_ids_1,\n",
    "                      attention_mask_1=b_input_mask_1,\n",
    "                      labels=b_labels)\n",
    "            b_labels = b_labels.unsqueeze(dim=1)\n",
    "            loss = F.binary_cross_entropy(out, b_labels.float())\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_loss / len(train_dataloader)  \n",
    "        loss_values.append(avg_train_loss)\n",
    "        valid_acc, y_real, y_pred = valid_model(model, valid_dataloader)\n",
    "        p, r, f1 = evaluate(y_real, y_pred)\n",
    "        epochs_results.append([avg_train_loss, valid_acc, p, r, f1])\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "    return epochs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, validation_dataloader):\n",
    "    print(\"Running Validation...\")    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    \n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids_0, b_input_mask_0 = batch[0].long(), batch[1]\n",
    "        b_input_ids_1, b_input_mask_1 = batch[2].long(), batch[3]\n",
    "        with torch.no_grad(): \n",
    "            out = model(input_ids_0=b_input_ids_0, \n",
    "                      attention_mask_0=b_input_mask_0, \n",
    "                      input_ids_1=b_input_ids_1,\n",
    "                      attention_mask_1=b_input_mask_1,\n",
    "                      labels=b_labels)\n",
    "        logits = out\n",
    "        #logits = logits.detach().cpu().numpy()\n",
    "        #label_ids = b_labels.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = flat_accuracy(np.array(logit), np.array(b_labels))\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "        pred = torch.max(logits, dim=1)[1]\n",
    "        y_true.append(b_labels)\n",
    "        y_pred.append(pred)        \n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    return eval_accuracy/nb_eval_steps, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        b_input_ids = b_input_ids.long()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        #logits = logits.detach().cpu().numpy()\n",
    "        #label_ids = b_labels.to('cpu').numpy()\n",
    "        # Store predictions and true labels\n",
    "        pred = torch.max(logits, dim=1)[1]\n",
    "        predictions.append(pred)\n",
    "        true_labels.append(b_labels)\n",
    "    print('    DONE.')\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_results = train_model(model, train_dataloader, valid_dataloader, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, validation, encoder_bert, evaluator_bert)\n",
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, testing, encoder_bert, evaluator_bert)\n",
    "acc, points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
