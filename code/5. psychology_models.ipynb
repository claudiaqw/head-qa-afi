{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'psychology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/basic_lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_cnn_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
