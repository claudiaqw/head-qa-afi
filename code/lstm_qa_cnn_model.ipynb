{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rural-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vectorizer, HeadQA, HeadQA_IR, clean_words, parse_dataset, parse_ir_dataset, random_oversamplig, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "from training import train, validate, evaluate, train_ir, validate_ir, load_embeddings_from_file, make_embedding_matrix\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reverse-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comprehensive-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_instances = parse_ir_dataset(training)\n",
    "#validation_instances = parse_ir_dataset(validation)\n",
    "#testing_instances = parse_ir_dataset(testing)\n",
    "\n",
    "#oversampled_training = random_oversamplig(training_instances)\n",
    "\n",
    "#save_dataset_to_pickle('../data/training_ir.pickle', training_instances)\n",
    "#save_dataset_to_pickle('../data/validation_ir.pickle', validation_instances)\n",
    "#save_dataset_to_pickle('../data/testing_ir.pickle', testing_instances)\n",
    "#save_dataset_to_pickle('../data/oversampled_training_ir.pickle', oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reasonable-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intermediate-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Los potenciales postsinápticos excitadores:',\n",
       " 'answer': 'Son de tipo todo o nada.',\n",
       " 'tok_qtext': ['Los', 'potenciales', 'postsinápticos', 'excitadores', ':'],\n",
       " 'tok_atext': ['Son', 'de', 'tipo', 'todo', 'o', 'nada', '.'],\n",
       " 'label': 0,\n",
       " 'category': 'biology'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "urban-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controlling-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "amino-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greek-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "transsexual-growth",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LSTM_QA(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, x_size, n_classes, embedding_size=300,\n",
    "                 padding_idx=0, pretrained_embeddings=None): \n",
    "        super(LSTM_QA, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=self.embedding_size,num_embeddings=self.vocab_size,\n",
    "                                    padding_idx=padding_idx)\n",
    "        else:\n",
    "            print('Loading pretrained embeddings...')\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding(embedding_dim=self.embedding_size, num_embeddings=self.vocab_size,\n",
    "                                    padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
    "            self.emb.weight.requires_grad = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, batch_first=True, dropout=0.5,bidirectional=True)\n",
    "        self.conv = nn.Conv1d(in_channels=self.hidden_size*2, out_channels=10, kernel_size=3)        \n",
    "        self.cosine = nn.CosineSimilarity(dim=1)\n",
    "        self.linear = nn.Linear(self.hidden_size*2, 64)  \n",
    "        self.linear1 = nn.Linear(64, self.n_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_0, x_1):\n",
    "        x_0 = self.emb(x_0)\n",
    "        x_1 = self.emb(x_1)\n",
    "        out_0, (ht_0, ct_0) = self.lstm(x_0)\n",
    "        out_1, (ht_1, ct_1) = self.lstm(x_1)        \n",
    "        x_0 = self.conv(ht_0)\n",
    "        x_1 = self.conv(ht_0)\n",
    "        print(x_0.shape)\n",
    "        print(x_1.shape)\n",
    "        \n",
    "        x = self.cosine(out_0, out_1)\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.softmax(x, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "incorrect-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "organized-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "# word_to_idx, embeddings = load_embeddings_from_file(embedding_file)\n",
    "\n",
    "# save_dataset_to_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle', word_to_idx)\n",
    "# save_dataset_to_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tough-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "silent-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "indirect-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ahead-replication",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 128, 3], expected input[2, 32, 64] to have 128 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-63d049390357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-519afa918d6e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_0, x_1)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mout_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mht_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct_0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mout_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mht_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mx_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mht_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 259\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    260\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 128, 3], expected input[2, 32, 64] to have 128 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "for x_0, x_1, y in train_dt:\n",
    "    out = model(x_0.long(), x_1.long())\n",
    "    print(out.shape)\n",
    "    break;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "vulnerable-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ir(model, dataloader):\n",
    "    model.eval()\n",
    "    loss, right, total = 0, 0, 0\n",
    "    y_true, y_preds = [], []\n",
    "    for x_0, x_1, y in dataloader:\n",
    "        batch = y.shape[0]\n",
    "        out = model(x_0.long(), x_1.long())\n",
    "        loss = F.binary_cross_entropy(out, y.float())\n",
    "        loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = torch.where(out > 0.4, 1, 0)\n",
    "        y_true.append(y)\n",
    "        y_preds.append(pred)\n",
    "        right += (pred == y).float().sum().item()\n",
    "    return loss/total, right/total, y_true, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "designing-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-fdc8d1c9533c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_ir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\mds\\TFM\\head-qa-afi\\code\\training.py\u001b[0m in \u001b[0;36mtrain_ir\u001b[1;34m(model, optimizer, train_dl, test_dl, validate, epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_results = train_ir(model, optimizer, train_dt, valid_dt, validate_ir, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, testing, trainset.encode, evaluator_ir)\n",
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, validation, trainset.encode, evaluator_ir)\n",
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/trained_models/lstm_qa_cnn'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
