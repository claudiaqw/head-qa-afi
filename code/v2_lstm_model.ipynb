{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vocabulary, Vectorizer, HeadQA, clean_words, parse_dataset, random_oversamplig, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "from training import train, validate, evaluate, evaluator, evaluate_better, get_optimizer\n",
    "\n",
    "from supervised_models import BasicLSTM\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "mixed_training = load_dataset_from_pickle('../data/mixed_oversampling_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(mixed_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=mixed_training, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "model = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.4147 valid loss 0.023 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.5952 valid loss 0.017 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.5801 valid loss 0.016 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.5876 valid loss 0.012 and accuracy 0.2500\n",
      "Epoch 4 train loss  0.5821 valid loss 0.010 and accuracy 0.2500\n",
      "Epoch 5 train loss  0.5932 valid loss 0.011 and accuracy 0.2500\n",
      "Epoch 6 train loss  0.5985 valid loss 0.009 and accuracy 0.2500\n",
      "Epoch 7 train loss  0.5818 valid loss 0.011 and accuracy 0.2500\n",
      "Epoch 8 train loss  0.5492 valid loss 0.011 and accuracy 0.2500\n",
      "Epoch 9 train loss  0.5690 valid loss 0.011 and accuracy 0.2500\n",
      "Epoch 10 train loss  0.5532 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 11 train loss  0.5580 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 12 train loss  0.5166 valid loss 0.020 and accuracy 0.2500\n",
      "Epoch 13 train loss  0.5309 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 14 train loss  0.5048 valid loss 0.013 and accuracy 0.2500\n",
      "Epoch 15 train loss  0.4910 valid loss 0.019 and accuracy 0.2500\n",
      "Epoch 16 train loss  0.5169 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 17 train loss  0.4888 valid loss 0.015 and accuracy 0.2500\n",
      "Epoch 18 train loss  0.4857 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 19 train loss  0.4734 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 20 train loss  0.4616 valid loss 0.014 and accuracy 0.2500\n",
      "Epoch 21 train loss  0.3849 valid loss 0.017 and accuracy 0.2500\n",
      "Epoch 22 train loss  0.3535 valid loss 0.018 and accuracy 0.2500\n",
      "Epoch 23 train loss  0.3241 valid loss 0.018 and accuracy 0.2500\n",
      "Epoch 24 train loss  0.2984 valid loss 0.018 and accuracy 0.2500\n",
      "Epoch 25 train loss  0.2814 valid loss 0.019 and accuracy 0.2504\n",
      "Epoch 26 train loss  0.2808 valid loss 0.016 and accuracy 0.2535\n",
      "Epoch 27 train loss  0.2891 valid loss 0.016 and accuracy 0.2559\n",
      "Epoch 28 train loss  0.2772 valid loss 0.016 and accuracy 0.2594\n",
      "Epoch 29 train loss  0.2540 valid loss 0.018 and accuracy 0.2550\n",
      "Epoch 30 train loss  0.2330 valid loss 0.019 and accuracy 0.2574\n",
      "Epoch 31 train loss  0.2431 valid loss 0.018 and accuracy 0.2662\n",
      "Epoch 32 train loss  0.2447 valid loss 0.018 and accuracy 0.2518\n",
      "Epoch 33 train loss  0.2387 valid loss 0.018 and accuracy 0.2645\n",
      "Epoch 34 train loss  0.2445 valid loss 0.019 and accuracy 0.2801\n",
      "Epoch 35 train loss  0.2319 valid loss 0.016 and accuracy 0.2869\n",
      "Epoch 36 train loss  0.2124 valid loss 0.017 and accuracy 0.2851\n",
      "Epoch 37 train loss  0.1963 valid loss 0.019 and accuracy 0.2838\n",
      "Epoch 38 train loss  0.1807 valid loss 0.020 and accuracy 0.2822\n",
      "Epoch 39 train loss  0.1709 valid loss 0.021 and accuracy 0.2790\n",
      "Epoch 40 train loss  0.1720 valid loss 0.021 and accuracy 0.2869\n",
      "Epoch 41 train loss  0.1593 valid loss 0.024 and accuracy 0.2803\n",
      "Epoch 42 train loss  0.1529 valid loss 0.025 and accuracy 0.2890\n",
      "Epoch 43 train loss  0.1533 valid loss 0.025 and accuracy 0.2849\n",
      "Epoch 44 train loss  0.1489 valid loss 0.024 and accuracy 0.2960\n",
      "Epoch 45 train loss  0.1429 valid loss 0.023 and accuracy 0.2967\n",
      "Epoch 46 train loss  0.1352 valid loss 0.025 and accuracy 0.2943\n",
      "Epoch 47 train loss  0.1397 valid loss 0.026 and accuracy 0.3083\n",
      "Epoch 48 train loss  0.1357 valid loss 0.025 and accuracy 0.2998\n",
      "Epoch 49 train loss  0.1303 valid loss 0.026 and accuracy 0.2980\n"
     ]
    }
   ],
   "source": [
    "training_results = train(model, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2621]), 66)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points = evaluate(model, validation, trainset.encode, evaluator)\n",
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2615]), 126)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points = evaluate(model, testing, trainset.encode, evaluator)\n",
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_to_pickle('results_v2/train_results_lstm.pickle', training_results)\n",
    "training_results = load_dataset_from_pickle('results_v2/train_results_lstm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/trained_models_v2/lstm'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (embeddings): Embedding(28831, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26219568,\n",
       " 11.0,\n",
       " [tensor(0.2965),\n",
       "  tensor(0.2522),\n",
       "  tensor(0.2622),\n",
       "  tensor(0.2468),\n",
       "  tensor(0.2743),\n",
       "  tensor(0.2412)],\n",
       " [42, 2, 11, -3, 22, -8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points, acc_list, points_list = evaluate_better(model, validation, trainset.encode, evaluator)\n",
    "acc, points, acc_list, points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26162377,\n",
       " 10.5,\n",
       " [tensor(0.2588),\n",
       "  tensor(0.2691),\n",
       "  tensor(0.2675),\n",
       "  tensor(0.2328),\n",
       "  tensor(0.2652),\n",
       "  tensor(0.2597),\n",
       "  tensor(0.2788),\n",
       "  tensor(0.2500),\n",
       "  tensor(0.2926),\n",
       "  tensor(0.2208),\n",
       "  tensor(0.2756),\n",
       "  tensor(0.2687)],\n",
       " [8, 17, 16, -16, 14, 9, 26, 0, 39, -27, 23, 17])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points, acc_list, points_list = evaluate_better(model, testing, trainset.encode, evaluator)\n",
    "acc, points, acc_list, points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
