{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vocabulary, Vectorizer, HeadQA, HeadQA_IR, clean_words, parse_dataset, parse_ir_dataset, random_oversamplig\n",
    "from training import train, validate, evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = parse_ir_dataset(training)\n",
    "validation_instances = parse_ir_dataset(validation)\n",
    "testing_instances = parse_ir_dataset(testing)\n",
    "\n",
    "oversampled_training = random_oversamplig(training_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.instances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-musical",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LSTM_QA(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, x_size, n_classes, embedding_dim=300): \n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.lstm_0 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm_1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        #nn.CosineSimilarity\n",
    "        self.linear = nn.Linear(hidden_dim, n_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        \n",
    "    def forward(self, x_0, x_1):\n",
    "        out_0, (ht_0, ct_0) = self.lstm_0(x_0)\n",
    "        out_1, (ht_1, ct_1) = self.lstm_0(x_1)\n",
    "        print(out_0.shape, out_1.shape)\n",
    "        print(ht_0.shape, ht_1.shape)\n",
    "        print(ct_0,shape, ct_1.shape)\n",
    "        return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
