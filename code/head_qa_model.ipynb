{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vectorizer, HeadQA, HeadQA_IR, clean_words, parse_dataset, parse_ir_dataset, random_oversamplig, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "from training import train, validate, evaluate, train_ir, validate_ir, load_embeddings_from_file, make_embedding_matrix\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_instances = parse_ir_dataset(training)\n",
    "#validation_instances = parse_ir_dataset(validation)\n",
    "#testing_instances = parse_ir_dataset(testing)\n",
    "\n",
    "#oversampled_training = random_oversamplig(training_instances)\n",
    "\n",
    "#save_dataset_to_pickle('../data/training_ir.pickle', training_instances)\n",
    "#save_dataset_to_pickle('../data/validation_ir.pickle', validation_instances)\n",
    "#save_dataset_to_pickle('../data/testing_ir.pickle', testing_instances)\n",
    "#save_dataset_to_pickle('../data/oversampled_training_ir.pickle', oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-growth",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LSTM_QA(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, x_size, n_classes, embedding_size=300,\n",
    "                 padding_idx=0, pretrained_embeddings=None): \n",
    "        super(LSTM_QA, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=self.embedding_size,num_embeddings=self.vocab_size,\n",
    "                                    padding_idx=padding_idx)\n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding(embedding_dim=self.embedding_size, num_embeddings=self.vocab_size,\n",
    "                                    padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
    "            self.emb.weight.requires_grad = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True, dropout=0.5,bidirectional=True)\n",
    "        self.cosine = nn.CosineSimilarity(dim=1)\n",
    "        self.linear = nn.Linear(self.hidden_size*2, self.n_classes)        \n",
    "        \n",
    "        \n",
    "    def forward(self, x_0, x_1):\n",
    "        x_0 = self.emb(x_0)\n",
    "        x_1 = self.emb(x_1)\n",
    "#         print(x_0.shape, x_1.shape)\n",
    "        out_0, (ht_0, ct_0) = self.lstm(x_0)\n",
    "        out_1, (ht_1, ct_1) = self.lstm(x_1)\n",
    "#         print('out', out_0.shape, out_1.shape)\n",
    "#         print('ht', ht_0.shape, ht_1.shape)\n",
    "#         print('ct', ct_0.shape, ct_1.shape)\n",
    "        x = self.cosine(out_0, out_1)\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, dim=0)\n",
    "#         print(x.shape)\n",
    "#         print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "# word_to_idx, embeddings = load_embeddings_from_file(embedding_file)\n",
    "\n",
    "# save_dataset_to_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle', word_to_idx)\n",
    "# save_dataset_to_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results = train_ir(model, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-buying",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
