{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'biology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  49.9159 valid loss 0.806 and accuracy 0.7288\n",
      "Epoch 1 train loss  48.5355 valid loss 0.921 and accuracy 0.7377\n",
      "Epoch 2 train loss  48.7181 valid loss 0.921 and accuracy 0.7366\n",
      "Epoch 3 train loss  48.6935 valid loss 0.921 and accuracy 0.7366\n",
      "Epoch 4 train loss  48.6484 valid loss 0.921 and accuracy 0.7355\n",
      "Epoch 5 train loss  48.5818 valid loss 0.921 and accuracy 0.7377\n",
      "Epoch 6 train loss  24.1746 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 7 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 8 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 9 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 10 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 11 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 12 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 13 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 14 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 15 train loss  50.4230 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 16 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 17 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 18 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 19 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 20 train loss  50.4228 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 21 train loss  50.4227 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 22 train loss  50.4227 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 23 train loss  50.4227 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 24 train loss  50.4226 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 25 train loss  50.4226 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 26 train loss  50.4225 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 27 train loss  50.4225 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 28 train loss  50.4225 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 29 train loss  50.4224 valid loss 2.762 and accuracy 0.2500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: biology\n",
      "accuracy: tensor([0.2566]), points: 6\n",
      "----------\n",
      "TEST Dominio: biology\n",
      "accuracy: tensor([0.2467]), points: -6\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.6168 valid loss 0.041 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.7854 valid loss 0.027 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.7089 valid loss 0.026 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.7011 valid loss 0.026 and accuracy 0.2500\n",
      "Epoch 4 train loss  0.6954 valid loss 0.026 and accuracy 0.2489\n",
      "Epoch 5 train loss  0.6871 valid loss 0.027 and accuracy 0.2511\n",
      "Epoch 6 train loss  0.6716 valid loss 0.027 and accuracy 0.2511\n",
      "Epoch 7 train loss  0.6325 valid loss 0.030 and accuracy 0.2623\n",
      "Epoch 8 train loss  0.5893 valid loss 0.032 and accuracy 0.3170\n",
      "Epoch 9 train loss  0.5181 valid loss 0.031 and accuracy 0.3638\n",
      "Epoch 10 train loss  0.4560 valid loss 0.029 and accuracy 0.5502\n",
      "Epoch 11 train loss  0.3794 valid loss 0.029 and accuracy 0.5993\n",
      "Epoch 12 train loss  0.3390 valid loss 0.030 and accuracy 0.6350\n",
      "Epoch 13 train loss  0.3025 valid loss 0.031 and accuracy 0.6328\n",
      "Epoch 14 train loss  0.2782 valid loss 0.036 and accuracy 0.5971\n",
      "Epoch 15 train loss  0.2568 valid loss 0.037 and accuracy 0.6306\n",
      "Epoch 16 train loss  0.2330 valid loss 0.035 and accuracy 0.6585\n",
      "Epoch 17 train loss  0.2157 valid loss 0.039 and accuracy 0.6562\n",
      "Epoch 18 train loss  0.1927 valid loss 0.038 and accuracy 0.6585\n",
      "Epoch 19 train loss  0.1833 valid loss 0.039 and accuracy 0.6696\n",
      "Epoch 20 train loss  0.1658 valid loss 0.040 and accuracy 0.6752\n",
      "Epoch 21 train loss  0.1639 valid loss 0.043 and accuracy 0.6652\n",
      "Epoch 22 train loss  0.1424 valid loss 0.046 and accuracy 0.6049\n",
      "Epoch 23 train loss  0.1413 valid loss 0.046 and accuracy 0.6674\n",
      "Epoch 24 train loss  0.1287 valid loss 0.044 and accuracy 0.6730\n",
      "Epoch 25 train loss  0.1294 valid loss 0.046 and accuracy 0.6484\n",
      "Epoch 26 train loss  0.1244 valid loss 0.048 and accuracy 0.6451\n",
      "Epoch 27 train loss  0.1194 valid loss 0.046 and accuracy 0.6395\n",
      "Epoch 28 train loss  0.1202 valid loss 0.052 and accuracy 0.6629\n",
      "Epoch 29 train loss  0.1024 valid loss 0.051 and accuracy 0.6518\n",
      "Epoch 30 train loss  0.1048 valid loss 0.050 and accuracy 0.6663\n",
      "Epoch 31 train loss  0.0963 valid loss 0.049 and accuracy 0.6507\n",
      "Epoch 32 train loss  0.0826 valid loss 0.052 and accuracy 0.6417\n",
      "Epoch 33 train loss  0.0841 valid loss 0.055 and accuracy 0.6830\n",
      "Epoch 34 train loss  0.0857 valid loss 0.055 and accuracy 0.6775\n",
      "Epoch 35 train loss  0.0762 valid loss 0.054 and accuracy 0.6696\n",
      "Epoch 36 train loss  0.0797 valid loss 0.053 and accuracy 0.6819\n",
      "Epoch 37 train loss  0.0724 valid loss 0.053 and accuracy 0.6719\n",
      "Epoch 38 train loss  0.0626 valid loss 0.056 and accuracy 0.6886\n",
      "Epoch 39 train loss  0.0717 valid loss 0.056 and accuracy 0.6496\n",
      "Epoch 40 train loss  0.0589 valid loss 0.057 and accuracy 0.6685\n",
      "Epoch 41 train loss  0.0574 valid loss 0.064 and accuracy 0.6730\n",
      "Epoch 42 train loss  0.0606 valid loss 0.059 and accuracy 0.6641\n",
      "Epoch 43 train loss  0.0580 valid loss 0.061 and accuracy 0.6908\n",
      "Epoch 44 train loss  0.0505 valid loss 0.062 and accuracy 0.6830\n",
      "Epoch 45 train loss  0.0486 valid loss 0.064 and accuracy 0.6797\n",
      "Epoch 46 train loss  0.0501 valid loss 0.067 and accuracy 0.6752\n",
      "Epoch 47 train loss  0.0440 valid loss 0.068 and accuracy 0.6730\n",
      "Epoch 48 train loss  0.0490 valid loss 0.063 and accuracy 0.6618\n",
      "Epoch 49 train loss  0.0469 valid loss 0.063 and accuracy 0.6629\n"
     ]
    }
   ],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: biology\n",
      "accuracy: tensor([0.2965]), points: 42\n",
      "----------\n",
      "TEST Dominio: biology\n",
      "accuracy: tensor([0.2974]), points: 86\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/basic_lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "described-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.3888 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 1 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 2 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 3 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 4 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 5 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 6 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 7 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 8 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 9 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 10 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 11 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 12 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 13 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 14 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 15 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 16 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 17 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 18 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 19 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 20 train loss  50.4464 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 21 train loss  50.3706 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 22 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 23 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 24 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 25 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 26 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 27 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 28 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 29 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 30 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 31 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 32 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 33 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 34 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 35 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 36 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 37 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 38 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 39 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 40 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 41 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 42 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 43 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 44 train loss  49.5536 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 45 train loss  48.2532 valid loss 0.822 and accuracy 0.7500\n",
      "Epoch 46 train loss  41.7636 valid loss 0.758 and accuracy 0.7500\n",
      "Epoch 47 train loss  39.0871 valid loss 0.710 and accuracy 0.7500\n",
      "Epoch 48 train loss  36.6086 valid loss 0.666 and accuracy 0.7500\n",
      "Epoch 49 train loss  34.2865 valid loss 0.624 and accuracy 0.7500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: biology\n",
      "accuracy: tensor([0.2257]), points: -22\n",
      "----------\n",
      "TEST Dominio: biology\n",
      "accuracy: tensor([0.2247]), points: -46\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5016 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4944 valid loss 0.003 and accuracy 0.7498\n",
      "Epoch 2 train loss  0.4683 valid loss 0.003 and accuracy 0.7265\n",
      "Epoch 3 train loss  0.4232 valid loss 0.004 and accuracy 0.6739\n",
      "Epoch 4 train loss  0.3587 valid loss 0.004 and accuracy 0.6822\n",
      "Epoch 5 train loss  0.2965 valid loss 0.005 and accuracy 0.6520\n",
      "Epoch 6 train loss  0.2583 valid loss 0.006 and accuracy 0.6820\n",
      "Epoch 7 train loss  0.1954 valid loss 0.008 and accuracy 0.6864\n",
      "Epoch 8 train loss  0.1719 valid loss 0.007 and accuracy 0.6879\n",
      "Epoch 9 train loss  0.1450 valid loss 0.007 and accuracy 0.6746\n",
      "Epoch 10 train loss  0.1233 valid loss 0.008 and accuracy 0.6842\n",
      "Epoch 11 train loss  0.0967 valid loss 0.006 and accuracy 0.6746\n",
      "Epoch 12 train loss  0.0820 valid loss 0.007 and accuracy 0.6572\n",
      "Epoch 13 train loss  0.0828 valid loss 0.007 and accuracy 0.6465\n",
      "Epoch 14 train loss  0.0711 valid loss 0.006 and accuracy 0.6631\n",
      "Epoch 15 train loss  0.0591 valid loss 0.007 and accuracy 0.6985\n",
      "Epoch 16 train loss  0.0641 valid loss 0.006 and accuracy 0.6704\n",
      "Epoch 17 train loss  0.0640 valid loss 0.009 and accuracy 0.6996\n",
      "Epoch 18 train loss  0.0546 valid loss 0.007 and accuracy 0.6603\n",
      "Epoch 19 train loss  0.0627 valid loss 0.009 and accuracy 0.6886\n",
      "Epoch 20 train loss  0.0496 valid loss 0.007 and accuracy 0.6813\n",
      "Epoch 21 train loss  0.0437 valid loss 0.008 and accuracy 0.6452\n",
      "Epoch 22 train loss  0.0411 valid loss 0.006 and accuracy 0.6616\n",
      "Epoch 23 train loss  0.0500 valid loss 0.009 and accuracy 0.6833\n",
      "Epoch 24 train loss  0.0518 valid loss 0.007 and accuracy 0.6776\n",
      "Epoch 25 train loss  0.0355 valid loss 0.007 and accuracy 0.6520\n",
      "Epoch 26 train loss  0.0319 valid loss 0.010 and accuracy 0.7033\n",
      "Epoch 27 train loss  0.0332 valid loss 0.010 and accuracy 0.6493\n",
      "Epoch 28 train loss  0.0373 valid loss 0.007 and accuracy 0.6778\n",
      "Epoch 29 train loss  0.0411 valid loss 0.009 and accuracy 0.6750\n",
      "Epoch 30 train loss  0.0358 valid loss 0.006 and accuracy 0.6831\n",
      "Epoch 31 train loss  0.0354 valid loss 0.008 and accuracy 0.6721\n",
      "Epoch 32 train loss  0.0336 valid loss 0.008 and accuracy 0.6796\n",
      "Epoch 33 train loss  0.0266 valid loss 0.011 and accuracy 0.6897\n",
      "Epoch 34 train loss  0.0316 valid loss 0.009 and accuracy 0.7013\n",
      "Epoch 35 train loss  0.0322 valid loss 0.010 and accuracy 0.6568\n",
      "Epoch 36 train loss  0.0325 valid loss 0.011 and accuracy 0.7182\n",
      "Epoch 37 train loss  0.0268 valid loss 0.009 and accuracy 0.6801\n",
      "Epoch 38 train loss  0.0287 valid loss 0.010 and accuracy 0.7184\n",
      "Epoch 39 train loss  0.0246 valid loss 0.009 and accuracy 0.6700\n",
      "Epoch 40 train loss  0.0213 valid loss 0.012 and accuracy 0.6923\n",
      "Epoch 41 train loss  0.0317 valid loss 0.011 and accuracy 0.6996\n",
      "Epoch 42 train loss  0.0338 valid loss 0.008 and accuracy 0.6892\n",
      "Epoch 43 train loss  0.0296 valid loss 0.012 and accuracy 0.7051\n",
      "Epoch 44 train loss  0.0243 valid loss 0.011 and accuracy 0.7075\n",
      "Epoch 45 train loss  0.0274 valid loss 0.009 and accuracy 0.6994\n",
      "Epoch 46 train loss  0.0247 valid loss 0.008 and accuracy 0.7044\n",
      "Epoch 47 train loss  0.0171 valid loss 0.010 and accuracy 0.6757\n",
      "Epoch 48 train loss  0.0197 valid loss 0.009 and accuracy 0.6711\n",
      "Epoch 49 train loss  0.0217 valid loss 0.010 and accuracy 0.6783\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: biology\n",
      "accuracy: tensor([0.3009]), points: 46\n",
      "----------\n",
      "TEST Dominio: biology\n",
      "accuracy: tensor([0.2952]), points: 82\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5018 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4938 valid loss 0.004 and accuracy 0.7502\n",
      "Epoch 2 train loss  0.4670 valid loss 0.004 and accuracy 0.7401\n",
      "Epoch 3 train loss  0.4160 valid loss 0.005 and accuracy 0.7145\n",
      "Epoch 4 train loss  0.3632 valid loss 0.006 and accuracy 0.6610\n",
      "Epoch 5 train loss  0.3058 valid loss 0.007 and accuracy 0.6803\n",
      "Epoch 6 train loss  0.2571 valid loss 0.006 and accuracy 0.6537\n",
      "Epoch 7 train loss  0.2124 valid loss 0.008 and accuracy 0.7094\n",
      "Epoch 8 train loss  0.1791 valid loss 0.011 and accuracy 0.7145\n",
      "Epoch 9 train loss  0.1458 valid loss 0.011 and accuracy 0.6888\n",
      "Epoch 10 train loss  0.1334 valid loss 0.011 and accuracy 0.6518\n",
      "Epoch 11 train loss  0.1155 valid loss 0.010 and accuracy 0.6390\n",
      "Epoch 12 train loss  0.0895 valid loss 0.014 and accuracy 0.6849\n",
      "Epoch 13 train loss  0.0848 valid loss 0.012 and accuracy 0.6456\n",
      "Epoch 14 train loss  0.0811 valid loss 0.012 and accuracy 0.6557\n",
      "Epoch 15 train loss  0.0680 valid loss 0.014 and accuracy 0.6868\n",
      "Epoch 16 train loss  0.0615 valid loss 0.012 and accuracy 0.6629\n",
      "Epoch 17 train loss  0.0595 valid loss 0.012 and accuracy 0.6963\n",
      "Epoch 18 train loss  0.0620 valid loss 0.010 and accuracy 0.7075\n",
      "Epoch 19 train loss  0.0572 valid loss 0.012 and accuracy 0.7059\n",
      "Epoch 20 train loss  0.0520 valid loss 0.011 and accuracy 0.6767\n",
      "Epoch 21 train loss  0.0529 valid loss 0.012 and accuracy 0.6801\n",
      "Epoch 22 train loss  0.0504 valid loss 0.014 and accuracy 0.7165\n",
      "Epoch 23 train loss  0.0391 valid loss 0.013 and accuracy 0.6824\n",
      "Epoch 24 train loss  0.0398 valid loss 0.012 and accuracy 0.7020\n",
      "Epoch 25 train loss  0.0482 valid loss 0.013 and accuracy 0.6915\n",
      "Epoch 26 train loss  0.0440 valid loss 0.009 and accuracy 0.7077\n",
      "Epoch 27 train loss  0.0351 valid loss 0.013 and accuracy 0.7057\n",
      "Epoch 28 train loss  0.0378 valid loss 0.012 and accuracy 0.7066\n",
      "Epoch 29 train loss  0.0307 valid loss 0.015 and accuracy 0.7101\n",
      "Epoch 30 train loss  0.0381 valid loss 0.012 and accuracy 0.6899\n",
      "Epoch 31 train loss  0.0319 valid loss 0.011 and accuracy 0.7099\n",
      "Epoch 32 train loss  0.0410 valid loss 0.015 and accuracy 0.7066\n",
      "Epoch 33 train loss  0.0376 valid loss 0.011 and accuracy 0.7160\n",
      "Epoch 34 train loss  0.0279 valid loss 0.013 and accuracy 0.7033\n",
      "Epoch 35 train loss  0.0234 valid loss 0.015 and accuracy 0.7072\n",
      "Epoch 36 train loss  0.0313 valid loss 0.016 and accuracy 0.7046\n",
      "Epoch 37 train loss  0.0274 valid loss 0.011 and accuracy 0.6710\n",
      "Epoch 38 train loss  0.0281 valid loss 0.014 and accuracy 0.6853\n",
      "Epoch 39 train loss  0.0318 valid loss 0.013 and accuracy 0.7039\n",
      "Epoch 40 train loss  0.0302 valid loss 0.014 and accuracy 0.7145\n",
      "Epoch 41 train loss  0.0268 valid loss 0.013 and accuracy 0.6818\n",
      "Epoch 42 train loss  0.0218 valid loss 0.016 and accuracy 0.6960\n",
      "Epoch 43 train loss  0.0282 valid loss 0.014 and accuracy 0.7153\n",
      "Epoch 44 train loss  0.0341 valid loss 0.015 and accuracy 0.6910\n",
      "Epoch 45 train loss  0.0413 valid loss 0.012 and accuracy 0.6949\n",
      "Epoch 46 train loss  0.0257 valid loss 0.014 and accuracy 0.6711\n",
      "Epoch 47 train loss  0.0180 valid loss 0.019 and accuracy 0.7226\n",
      "Epoch 48 train loss  0.0218 valid loss 0.015 and accuracy 0.6926\n",
      "Epoch 49 train loss  0.0237 valid loss 0.013 and accuracy 0.6840\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: biology\n",
      "accuracy: tensor([0.2478]), points: -2\n",
      "----------\n",
      "TEST Dominio: biology\n",
      "accuracy: tensor([0.2885]), points: 70\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_cnn_qa:{CATEGORY}'\n",
    "torch.save(lstm_cnn_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
