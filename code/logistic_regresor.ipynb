{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import Vocabulary, Vectorizer, HeadQA, clean_words, parse_dataset, random_oversamplig\n",
    "from training import train, validate, evaluate\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\CLAUDIA\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\d6803d1e84273cdc4a2cf3c5102945d166555f47b299ecbc5266d582f408f8e2)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# data_en = load_dataset('head_qa', 'en')\n",
    "data_es = load_dataset('head_qa', 'es' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Cuaderno_2013_1_B', 'year': '2013', 'category': 'biology', 'qid': 1, 'qtext': 'Los potenciales postsin√°pticos excitadores:', 'ra': 3, 'image': '', 'answers': [{'aid': 1, 'atext': 'Son de tipo todo o nada.'}, {'aid': 2, 'atext': 'Son hiperpolarizantes.'}, {'aid': 3, 'atext': 'Se pueden sumar.'}, {'aid': 4, 'atext': 'Se propagan a largas distancias.'}, {'aid': 5, 'atext': 'Presentan un periodo refractario.'}]}\n"
     ]
    }
   ],
   "source": [
    "for d in training:\n",
    "    print(d)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = parse_dataset(training)\n",
    "validation_instances = parse_dataset(validation)\n",
    "testing_instances = parse_dataset(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_training = random_oversamplig(training_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(oversampled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, x_size, n_classes): \n",
    "        super(LogisticRegression, self).__init__()             \n",
    "        self.linear = nn.Linear(x_size, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, dim=0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr=0.01, wd=0.0):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(model, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  21.6421 valid loss 0.171 and accuracy 23.9882\n",
      "Epoch 1 train loss  21.6648 valid loss 0.133 and accuracy 24.0059\n",
      "Epoch 2 train loss  21.7195 valid loss 0.133 and accuracy 24.0000\n",
      "Epoch 3 train loss  21.7747 valid loss 0.227 and accuracy 24.0059\n",
      "Epoch 4 train loss  21.5394 valid loss 0.114 and accuracy 24.0118\n",
      "Epoch 5 train loss  21.7303 valid loss 0.133 and accuracy 23.9882\n",
      "Epoch 6 train loss  21.7257 valid loss 0.171 and accuracy 24.0059\n",
      "Epoch 7 train loss  21.7036 valid loss 0.152 and accuracy 23.9882\n",
      "Epoch 8 train loss  21.7344 valid loss 0.227 and accuracy 24.0000\n",
      "Epoch 9 train loss  21.6570 valid loss 0.152 and accuracy 24.0118\n",
      "Epoch 10 train loss  21.5832 valid loss 0.133 and accuracy 24.0000\n",
      "Epoch 11 train loss  21.6190 valid loss 0.076 and accuracy 23.9941\n",
      "Epoch 12 train loss  21.6654 valid loss 0.095 and accuracy 23.9882\n",
      "Epoch 13 train loss  21.5461 valid loss 0.152 and accuracy 24.0059\n",
      "Epoch 14 train loss  21.7991 valid loss 0.190 and accuracy 24.0059\n",
      "Epoch 15 train loss  21.6937 valid loss 0.171 and accuracy 24.0000\n",
      "Epoch 16 train loss  21.7358 valid loss 0.152 and accuracy 23.9882\n",
      "Epoch 17 train loss  21.5572 valid loss 0.114 and accuracy 23.9941\n",
      "Epoch 18 train loss  21.7273 valid loss 0.095 and accuracy 24.0294\n",
      "Epoch 19 train loss  21.7408 valid loss 0.227 and accuracy 23.9941\n",
      "Epoch 20 train loss  21.7620 valid loss 0.114 and accuracy 24.0000\n",
      "Epoch 21 train loss  21.7818 valid loss 0.265 and accuracy 23.9824\n",
      "Epoch 22 train loss  21.5954 valid loss 0.152 and accuracy 23.9882\n",
      "Epoch 23 train loss  21.6902 valid loss 0.171 and accuracy 23.9882\n",
      "Epoch 24 train loss  21.6767 valid loss 0.152 and accuracy 24.0118\n",
      "Epoch 25 train loss  21.7308 valid loss 0.171 and accuracy 23.9941\n",
      "Epoch 26 train loss  21.7278 valid loss 0.114 and accuracy 24.0176\n",
      "Epoch 27 train loss  21.6191 valid loss 0.190 and accuracy 24.0000\n",
      "Epoch 28 train loss  21.7085 valid loss 0.133 and accuracy 24.0118\n",
      "Epoch 29 train loss  21.6067 valid loss 0.114 and accuracy 24.0118\n",
      "Epoch 30 train loss  21.5664 valid loss 0.227 and accuracy 23.9765\n",
      "Epoch 31 train loss  21.7895 valid loss 0.133 and accuracy 24.0000\n",
      "Epoch 32 train loss  21.6345 valid loss 0.209 and accuracy 24.0000\n",
      "Epoch 33 train loss  21.6190 valid loss 0.171 and accuracy 24.0000\n",
      "Epoch 34 train loss  21.6555 valid loss 0.152 and accuracy 24.0000\n",
      "Epoch 35 train loss  21.6647 valid loss 0.038 and accuracy 24.0118\n",
      "Epoch 36 train loss  21.7592 valid loss 0.190 and accuracy 23.9882\n",
      "Epoch 37 train loss  21.8352 valid loss 0.190 and accuracy 23.9941\n",
      "Epoch 38 train loss  21.5131 valid loss 0.152 and accuracy 24.0118\n",
      "Epoch 39 train loss  21.6795 valid loss 0.095 and accuracy 23.9941\n",
      "Epoch 40 train loss  21.5386 valid loss 0.190 and accuracy 24.0118\n",
      "Epoch 41 train loss  21.5655 valid loss 0.152 and accuracy 24.0059\n",
      "Epoch 42 train loss  21.7437 valid loss 0.095 and accuracy 23.9941\n",
      "Epoch 43 train loss  21.6696 valid loss 0.205 and accuracy 24.0294\n",
      "Epoch 44 train loss  21.7501 valid loss 0.209 and accuracy 24.0059\n",
      "Epoch 45 train loss  21.7281 valid loss 0.152 and accuracy 24.0176\n",
      "Epoch 46 train loss  21.7143 valid loss 0.076 and accuracy 24.0118\n",
      "Epoch 47 train loss  21.6764 valid loss 0.190 and accuracy 24.0059\n",
      "Epoch 48 train loss  21.5739 valid loss 0.133 and accuracy 24.0000\n",
      "Epoch 49 train loss  21.6674 valid loss 0.133 and accuracy 24.0000\n"
     ]
    }
   ],
   "source": [
    "training_results = train(model, optimizer, train_dt, valid_dt, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, validation, trainset.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2474]), -14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, points = evaluate(model, testing, trainset.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2666]), 182)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/trained_models/logistic_regressor'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
