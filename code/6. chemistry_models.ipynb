{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from utils_data import  Vocabulary, Vectorizer, HeadQA, HeadQA_IR\n",
    "from utils_data import parse_dataset, parse_ir_dataset, random_oversamplig, random_undersampling\n",
    "from utils_data import filter_by_category, save_dataset_to_pickle, load_dataset_from_pickle\n",
    "import training\n",
    "from training import get_optimizer, train, train_ir, validate, validate_ir, evaluator, evaluator_ir, evaluate\n",
    "from training import load_embeddings_from_file, make_embedding_matrix\n",
    "from training import pad_seq, encoder_bert, encoder_bert_ir, encoder_bert_instance, encoder_bert_ir_instance\n",
    "from training import evaluator_bert, evaluator_bert_ir\n",
    "\n",
    "from supervised_models import LogisticRegression, BasicLSTM, BiLSTM_model\n",
    "from ir_models import LSTM_QA, LSTM_CNN_QA, BERT_QA\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 'chemistry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset head_qa (C:\\Users\\tec005m\\.cache\\huggingface\\datasets\\head_qa\\es\\1.1.0\\473dc5357942a3ff52963bd73cad0d167bd1bbc1ca5ca0732ee7372b480dd735)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_es = load_dataset('head_qa', 'es' )\n",
    "training, validation, testing = data_es['train'], data_es['validation'], data_es['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-tennessee",
   "metadata": {},
   "source": [
    "### Modelos supervisados puros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incident-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing.pickle')\n",
    "\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behavioral-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subtle-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_training(training_categ)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sonic-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA(instances=training_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "validset = HeadQA(instances=validation_categ, vectorizer=vectorizer, right_padding=False, max_length=30)\n",
    "testset = HeadQA(instances=testing_categ, vectorizer=vectorizer, right_padding=False, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-acceptance",
   "metadata": {},
   "source": [
    "#### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(trainset.max_length, 1)\n",
    "optimizer = get_optimizer(logistic_regressor, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enabling-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  51.2619 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 1 train loss  50.4455 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 2 train loss  50.4435 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 3 train loss  50.4303 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 4 train loss  50.4188 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 5 train loss  50.4054 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 6 train loss  50.7387 valid loss 0.921 and accuracy 0.7455\n",
      "Epoch 7 train loss  50.3909 valid loss 0.921 and accuracy 0.7455\n",
      "Epoch 8 train loss  50.3906 valid loss 0.921 and accuracy 0.7455\n",
      "Epoch 9 train loss  50.3903 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 10 train loss  50.3899 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 11 train loss  50.3894 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 12 train loss  50.4187 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 13 train loss  50.3921 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 14 train loss  50.3917 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 15 train loss  50.3911 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 16 train loss  50.3906 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 17 train loss  50.3900 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 18 train loss  50.3894 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 19 train loss  50.3887 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 20 train loss  50.3880 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 21 train loss  50.3873 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 22 train loss  50.3929 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 23 train loss  50.3843 valid loss 0.921 and accuracy 0.7500\n",
      "Epoch 24 train loss  50.4567 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 25 train loss  50.4742 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 26 train loss  50.5094 valid loss 0.921 and accuracy 0.7467\n",
      "Epoch 27 train loss  50.4156 valid loss 0.921 and accuracy 0.7478\n",
      "Epoch 28 train loss  50.4150 valid loss 0.921 and accuracy 0.7489\n",
      "Epoch 29 train loss  50.4144 valid loss 0.921 and accuracy 0.7489\n"
     ]
    }
   ],
   "source": [
    "training_results = train(logistic_regressor, optimizer, train_dt, valid_dt, validate, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "referenced-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: chemistry\n",
      "accuracy: tensor([0.2149]), points: -32\n",
      "----------\n",
      "TEST Dominio: chemistry\n",
      "accuracy: tensor([0.2424]), points: -14\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(logistic_regressor, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(logistic_regressor, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spoken-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/logistic_regressor_{CATEGORY}'\n",
    "torch.save(logistic_regressor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-muscle",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rolled-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = BasicLSTM(len(vocab), 64, trainset.max_length, 1, embedding_dim=100)\n",
    "optimizer = get_optimizer(lstm, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "laughing-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.6326 valid loss 0.037 and accuracy 0.2500\n",
      "Epoch 1 train loss  0.7450 valid loss 0.027 and accuracy 0.2500\n",
      "Epoch 2 train loss  0.7008 valid loss 0.026 and accuracy 0.2500\n",
      "Epoch 3 train loss  0.6944 valid loss 0.026 and accuracy 0.2500\n",
      "Epoch 4 train loss  0.6887 valid loss 0.026 and accuracy 0.2511\n",
      "Epoch 5 train loss  0.6829 valid loss 0.026 and accuracy 0.2545\n",
      "Epoch 6 train loss  0.6671 valid loss 0.027 and accuracy 0.2556\n",
      "Epoch 7 train loss  0.6441 valid loss 0.027 and accuracy 0.2746\n",
      "Epoch 8 train loss  0.6027 valid loss 0.028 and accuracy 0.3371\n",
      "Epoch 9 train loss  0.5487 valid loss 0.029 and accuracy 0.3705\n",
      "Epoch 10 train loss  0.4892 valid loss 0.028 and accuracy 0.4531\n",
      "Epoch 11 train loss  0.4379 valid loss 0.027 and accuracy 0.5636\n",
      "Epoch 12 train loss  0.3871 valid loss 0.029 and accuracy 0.5647\n",
      "Epoch 13 train loss  0.3538 valid loss 0.029 and accuracy 0.5882\n",
      "Epoch 14 train loss  0.3214 valid loss 0.031 and accuracy 0.5960\n",
      "Epoch 15 train loss  0.2987 valid loss 0.032 and accuracy 0.6105\n",
      "Epoch 16 train loss  0.2782 valid loss 0.033 and accuracy 0.6049\n",
      "Epoch 17 train loss  0.2625 valid loss 0.036 and accuracy 0.6105\n",
      "Epoch 18 train loss  0.2415 valid loss 0.036 and accuracy 0.6138\n",
      "Epoch 19 train loss  0.2358 valid loss 0.037 and accuracy 0.6172\n",
      "Epoch 20 train loss  0.2244 valid loss 0.039 and accuracy 0.6250\n",
      "Epoch 21 train loss  0.2055 valid loss 0.039 and accuracy 0.6250\n",
      "Epoch 22 train loss  0.2050 valid loss 0.039 and accuracy 0.6194\n",
      "Epoch 23 train loss  0.2036 valid loss 0.040 and accuracy 0.6373\n",
      "Epoch 24 train loss  0.1863 valid loss 0.042 and accuracy 0.6362\n",
      "Epoch 25 train loss  0.1892 valid loss 0.044 and accuracy 0.6350\n",
      "Epoch 26 train loss  0.1798 valid loss 0.050 and accuracy 0.6261\n",
      "Epoch 27 train loss  0.1824 valid loss 0.049 and accuracy 0.6350\n",
      "Epoch 28 train loss  0.1659 valid loss 0.047 and accuracy 0.6440\n",
      "Epoch 29 train loss  0.1678 valid loss 0.047 and accuracy 0.6395\n",
      "Epoch 30 train loss  0.1620 valid loss 0.049 and accuracy 0.6462\n",
      "Epoch 31 train loss  0.1582 valid loss 0.050 and accuracy 0.6451\n",
      "Epoch 32 train loss  0.1475 valid loss 0.049 and accuracy 0.6507\n",
      "Epoch 33 train loss  0.1482 valid loss 0.050 and accuracy 0.6395\n",
      "Epoch 34 train loss  0.1389 valid loss 0.052 and accuracy 0.6395\n",
      "Epoch 35 train loss  0.1495 valid loss 0.051 and accuracy 0.6417\n",
      "Epoch 36 train loss  0.1407 valid loss 0.054 and accuracy 0.6384\n",
      "Epoch 37 train loss  0.1329 valid loss 0.054 and accuracy 0.6328\n",
      "Epoch 38 train loss  0.1354 valid loss 0.054 and accuracy 0.6462\n",
      "Epoch 39 train loss  0.1309 valid loss 0.055 and accuracy 0.6529\n",
      "Epoch 40 train loss  0.1345 valid loss 0.055 and accuracy 0.6484\n",
      "Epoch 41 train loss  0.1291 valid loss 0.055 and accuracy 0.6585\n",
      "Epoch 42 train loss  0.1249 valid loss 0.057 and accuracy 0.6440\n",
      "Epoch 43 train loss  0.1247 valid loss 0.057 and accuracy 0.6484\n",
      "Epoch 44 train loss  0.1153 valid loss 0.059 and accuracy 0.6596\n",
      "Epoch 45 train loss  0.1201 valid loss 0.059 and accuracy 0.6518\n",
      "Epoch 46 train loss  0.1149 valid loss 0.061 and accuracy 0.6507\n",
      "Epoch 47 train loss  0.1138 valid loss 0.060 and accuracy 0.6462\n",
      "Epoch 48 train loss  0.1170 valid loss 0.060 and accuracy 0.6484\n",
      "Epoch 49 train loss  0.1144 valid loss 0.062 and accuracy 0.6462\n"
     ]
    }
   ],
   "source": [
    "training_results = train(lstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neural-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: chemistry\n",
      "accuracy: tensor([0.2632]), points: 12\n",
      "----------\n",
      "TEST Dominio: chemistry\n",
      "accuracy: tensor([0.3057]), points: 102\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "animated-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/basic_lstm_{CATEGORY}'\n",
    "torch.save(lstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-northwest",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "miniature-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tec005m\\Anaconda3\\envs\\afi\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTM_model(embedding_matrix.shape[1], embedding_matrix.shape[0], 1, \n",
    "                     pretrained_embeddings=embedding_matrix, max_length=trainset.max_length)\n",
    "optimizer = get_optimizer(bilstm, lr = 0.01, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "described-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.3688 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 1 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 2 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 3 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 4 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 5 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 6 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 7 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 8 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 9 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 10 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 11 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 12 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 13 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 14 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 15 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 16 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 17 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 18 train loss  10.6856 valid loss 2.569 and accuracy 0.2500\n",
      "Epoch 19 train loss  1.6831 valid loss 0.861 and accuracy 0.2500\n",
      "Epoch 20 train loss  1.0483 valid loss 0.673 and accuracy 0.2500\n",
      "Epoch 21 train loss  0.8970 valid loss 2.467 and accuracy 0.2500\n",
      "Epoch 22 train loss  2.1477 valid loss 0.301 and accuracy 0.2500\n",
      "Epoch 23 train loss  0.8888 valid loss 2.081 and accuracy 0.2500\n",
      "Epoch 24 train loss  2.2800 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 25 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 26 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 27 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 28 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 29 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 30 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 31 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 32 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 33 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 34 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 35 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 36 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 37 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 38 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 39 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 40 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 41 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 42 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 43 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 44 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 45 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 46 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 47 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 48 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n",
      "Epoch 49 train loss  49.5652 valid loss 2.762 and accuracy 0.2500\n"
     ]
    }
   ],
   "source": [
    "training_results = train(bilstm, optimizer, train_dt, valid_dt, validate, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "operating-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: chemistry\n",
      "accuracy: tensor([0.2061]), points: -40\n",
      "----------\n",
      "TEST Dominio: chemistry\n",
      "accuracy: tensor([0.2402]), points: -18\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(bilstm, dev_categ, trainset.encode, evaluator)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(bilstm, test_categ, trainset.encode, evaluator)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instrumental-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/bilstm_{CATEGORY}'\n",
    "torch.save(bilstm.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-oliver",
   "metadata": {},
   "source": [
    "### Modelos supervisados IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "swiss-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instances = load_dataset_from_pickle('../data/training_ir.pickle')\n",
    "validation_instances = load_dataset_from_pickle('../data/validation_ir.pickle')\n",
    "testing_instances = load_dataset_from_pickle('../data/testing_ir.pickle')\n",
    "oversampled_training = load_dataset_from_pickle('../data/oversampled_training_ir.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_categ = filter_by_category(oversampled_training, category=CATEGORY)\n",
    "validation_categ = filter_by_category(validation_instances, category=CATEGORY)\n",
    "testing_categ = filter_by_category(testing_instances, category=CATEGORY)\n",
    "\n",
    "dev_categ = filter_by_category(validation, category=CATEGORY)\n",
    "test_categ = filter_by_category(testing, category=CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excessive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer.vectorize_ir_dataset(oversampled_training)\n",
    "vocab = vectorizer.sentence_vocab\n",
    "label_vocab = vectorizer.label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geological-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = HeadQA_IR(instances=training_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "validset = HeadQA_IR(instances=validation_instances, vectorizer=vectorizer, right_padding=False, max_length=15)\n",
    "testset = HeadQA_IR(instances=testing_instances, vectorizer=vectorizer, right_padding=False, max_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "numerous-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dt = DataLoader(trainset, batch_size=batch_size,drop_last=True)\n",
    "valid_dt = DataLoader(validset, batch_size=batch_size,drop_last=True)\n",
    "test_dt = DataLoader(testset, batch_size=batch_size,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hawaiian-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = load_dataset_from_pickle('trained_models/biomedical_embeddings/word_to_index_ir.pickle')\n",
    "embeddings = load_dataset_from_pickle('trained_models/biomedical_embeddings/wordvectors_ir.pickle')\n",
    "embedding_file = \"trained_models/biomedical_embeddings/Scielo_wiki_FastText300.vec\"\n",
    "words = vocab.vocab2index.keys()\n",
    "embedding_matrix = make_embedding_matrix(embedding_file, list(words), word_to_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-christianity",
   "metadata": {},
   "source": [
    "#### LSTM-QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "medieval-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_qa = LSTM_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5016 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4948 valid loss 0.003 and accuracy 0.7498\n",
      "Epoch 2 train loss  0.4721 valid loss 0.003 and accuracy 0.7441\n",
      "Epoch 3 train loss  0.4231 valid loss 0.003 and accuracy 0.6813\n",
      "Epoch 4 train loss  0.3735 valid loss 0.004 and accuracy 0.6792\n",
      "Epoch 5 train loss  0.3168 valid loss 0.004 and accuracy 0.6816\n",
      "Epoch 6 train loss  0.2699 valid loss 0.005 and accuracy 0.7031\n",
      "Epoch 7 train loss  0.2033 valid loss 0.006 and accuracy 0.6472\n",
      "Epoch 8 train loss  0.1693 valid loss 0.006 and accuracy 0.6551\n",
      "Epoch 9 train loss  0.1365 valid loss 0.007 and accuracy 0.6728\n",
      "Epoch 10 train loss  0.1184 valid loss 0.007 and accuracy 0.6822\n",
      "Epoch 11 train loss  0.1045 valid loss 0.008 and accuracy 0.6824\n",
      "Epoch 12 train loss  0.0855 valid loss 0.008 and accuracy 0.6858\n",
      "Epoch 13 train loss  0.0809 valid loss 0.009 and accuracy 0.6969\n",
      "Epoch 14 train loss  0.0741 valid loss 0.010 and accuracy 0.7085\n",
      "Epoch 15 train loss  0.0651 valid loss 0.009 and accuracy 0.6583\n",
      "Epoch 16 train loss  0.0648 valid loss 0.009 and accuracy 0.6904\n",
      "Epoch 17 train loss  0.0699 valid loss 0.009 and accuracy 0.7055\n",
      "Epoch 18 train loss  0.0541 valid loss 0.009 and accuracy 0.6849\n",
      "Epoch 19 train loss  0.0519 valid loss 0.009 and accuracy 0.7164\n",
      "Epoch 20 train loss  0.0540 valid loss 0.007 and accuracy 0.6805\n",
      "Epoch 21 train loss  0.0487 valid loss 0.010 and accuracy 0.7074\n",
      "Epoch 22 train loss  0.0427 valid loss 0.010 and accuracy 0.6864\n",
      "Epoch 23 train loss  0.0577 valid loss 0.011 and accuracy 0.7118\n",
      "Epoch 24 train loss  0.0478 valid loss 0.009 and accuracy 0.6838\n",
      "Epoch 25 train loss  0.0426 valid loss 0.012 and accuracy 0.6960\n",
      "Epoch 26 train loss  0.0444 valid loss 0.010 and accuracy 0.6976\n",
      "Epoch 27 train loss  0.0371 valid loss 0.009 and accuracy 0.6820\n",
      "Epoch 28 train loss  0.0373 valid loss 0.011 and accuracy 0.6961\n",
      "Epoch 29 train loss  0.0420 valid loss 0.009 and accuracy 0.6963\n",
      "Epoch 30 train loss  0.0355 valid loss 0.011 and accuracy 0.6932\n",
      "Epoch 31 train loss  0.0317 valid loss 0.009 and accuracy 0.6980\n",
      "Epoch 32 train loss  0.0336 valid loss 0.012 and accuracy 0.7215\n",
      "Epoch 33 train loss  0.0316 valid loss 0.011 and accuracy 0.7070\n",
      "Epoch 34 train loss  0.0356 valid loss 0.013 and accuracy 0.6892\n",
      "Epoch 35 train loss  0.0436 valid loss 0.011 and accuracy 0.7050\n",
      "Epoch 36 train loss  0.0344 valid loss 0.011 and accuracy 0.7017\n",
      "Epoch 37 train loss  0.0250 valid loss 0.012 and accuracy 0.6952\n",
      "Epoch 38 train loss  0.0272 valid loss 0.012 and accuracy 0.7101\n",
      "Epoch 39 train loss  0.0275 valid loss 0.012 and accuracy 0.7096\n",
      "Epoch 40 train loss  0.0299 valid loss 0.011 and accuracy 0.6857\n",
      "Epoch 41 train loss  0.0288 valid loss 0.014 and accuracy 0.7154\n",
      "Epoch 42 train loss  0.0233 valid loss 0.011 and accuracy 0.6737\n",
      "Epoch 43 train loss  0.0244 valid loss 0.012 and accuracy 0.6919\n",
      "Epoch 44 train loss  0.0270 valid loss 0.011 and accuracy 0.6908\n",
      "Epoch 45 train loss  0.0273 valid loss 0.007 and accuracy 0.6689\n",
      "Epoch 46 train loss  0.0294 valid loss 0.013 and accuracy 0.7042\n",
      "Epoch 47 train loss  0.0278 valid loss 0.009 and accuracy 0.6912\n",
      "Epoch 48 train loss  0.0258 valid loss 0.012 and accuracy 0.6961\n",
      "Epoch 49 train loss  0.0177 valid loss 0.012 and accuracy 0.6996\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dress-phenomenon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: chemistry\n",
      "accuracy: tensor([0.2544]), points: 4\n",
      "----------\n",
      "TEST Dominio: chemistry\n",
      "accuracy: tensor([0.2445]), points: -10\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caroline-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_qa_{CATEGORY}'\n",
    "torch.save(lstm_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-worker",
   "metadata": {},
   "source": [
    "#### LSTM-QA/CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "organizational-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained embeddings...\n"
     ]
    }
   ],
   "source": [
    "lstm_cnn_qa = LSTM_CNN_QA(vocab_size=len(vocab), hidden_size=64, x_size=trainset.max_length, n_classes=1, embedding_size=300,\n",
    "               pretrained_embeddings=embedding_matrix)\n",
    "optimizer = get_optimizer(lstm_cnn_qa, lr = 0.001, wd = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "capital-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss  0.5020 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 1 train loss  0.4957 valid loss 0.003 and accuracy 0.7500\n",
      "Epoch 2 train loss  0.4693 valid loss 0.003 and accuracy 0.7430\n",
      "Epoch 3 train loss  0.4211 valid loss 0.004 and accuracy 0.6958\n",
      "Epoch 4 train loss  0.3601 valid loss 0.004 and accuracy 0.7085\n",
      "Epoch 5 train loss  0.2905 valid loss 0.005 and accuracy 0.6991\n",
      "Epoch 6 train loss  0.2380 valid loss 0.005 and accuracy 0.5949\n",
      "Epoch 7 train loss  0.2209 valid loss 0.005 and accuracy 0.6691\n",
      "Epoch 8 train loss  0.1688 valid loss 0.007 and accuracy 0.7044\n",
      "Epoch 9 train loss  0.1455 valid loss 0.009 and accuracy 0.7221\n",
      "Epoch 10 train loss  0.1297 valid loss 0.010 and accuracy 0.7182\n",
      "Epoch 11 train loss  0.1143 valid loss 0.010 and accuracy 0.6983\n",
      "Epoch 12 train loss  0.1113 valid loss 0.008 and accuracy 0.6489\n",
      "Epoch 13 train loss  0.0968 valid loss 0.007 and accuracy 0.6730\n",
      "Epoch 14 train loss  0.0856 valid loss 0.008 and accuracy 0.6513\n",
      "Epoch 15 train loss  0.0746 valid loss 0.009 and accuracy 0.6932\n",
      "Epoch 16 train loss  0.0707 valid loss 0.008 and accuracy 0.7007\n",
      "Epoch 17 train loss  0.0621 valid loss 0.009 and accuracy 0.6952\n",
      "Epoch 18 train loss  0.0625 valid loss 0.009 and accuracy 0.7046\n",
      "Epoch 19 train loss  0.0517 valid loss 0.010 and accuracy 0.6976\n",
      "Epoch 20 train loss  0.0479 valid loss 0.009 and accuracy 0.7131\n",
      "Epoch 21 train loss  0.0464 valid loss 0.011 and accuracy 0.7051\n",
      "Epoch 22 train loss  0.0491 valid loss 0.010 and accuracy 0.6886\n",
      "Epoch 23 train loss  0.0494 valid loss 0.010 and accuracy 0.6934\n",
      "Epoch 24 train loss  0.0477 valid loss 0.010 and accuracy 0.7274\n",
      "Epoch 25 train loss  0.0443 valid loss 0.009 and accuracy 0.6901\n",
      "Epoch 26 train loss  0.0481 valid loss 0.010 and accuracy 0.7033\n",
      "Epoch 27 train loss  0.0475 valid loss 0.010 and accuracy 0.6914\n",
      "Epoch 28 train loss  0.0412 valid loss 0.012 and accuracy 0.6921\n",
      "Epoch 29 train loss  0.0387 valid loss 0.009 and accuracy 0.6794\n",
      "Epoch 30 train loss  0.0357 valid loss 0.012 and accuracy 0.6972\n",
      "Epoch 31 train loss  0.0438 valid loss 0.011 and accuracy 0.7158\n",
      "Epoch 32 train loss  0.0356 valid loss 0.010 and accuracy 0.6895\n",
      "Epoch 33 train loss  0.0297 valid loss 0.009 and accuracy 0.6814\n",
      "Epoch 34 train loss  0.0331 valid loss 0.012 and accuracy 0.7110\n",
      "Epoch 35 train loss  0.0341 valid loss 0.011 and accuracy 0.6954\n",
      "Epoch 36 train loss  0.0312 valid loss 0.013 and accuracy 0.7035\n",
      "Epoch 37 train loss  0.0327 valid loss 0.013 and accuracy 0.6853\n",
      "Epoch 38 train loss  0.0344 valid loss 0.011 and accuracy 0.6978\n",
      "Epoch 39 train loss  0.0370 valid loss 0.012 and accuracy 0.6822\n",
      "Epoch 40 train loss  0.0336 valid loss 0.013 and accuracy 0.6930\n",
      "Epoch 41 train loss  0.0288 valid loss 0.013 and accuracy 0.6840\n",
      "Epoch 42 train loss  0.0321 valid loss 0.012 and accuracy 0.6700\n",
      "Epoch 43 train loss  0.0356 valid loss 0.014 and accuracy 0.7090\n",
      "Epoch 44 train loss  0.0266 valid loss 0.015 and accuracy 0.7066\n",
      "Epoch 45 train loss  0.0241 valid loss 0.014 and accuracy 0.6921\n",
      "Epoch 46 train loss  0.0256 valid loss 0.016 and accuracy 0.7081\n",
      "Epoch 47 train loss  0.0222 valid loss 0.014 and accuracy 0.6761\n",
      "Epoch 48 train loss  0.0371 valid loss 0.014 and accuracy 0.6884\n",
      "Epoch 49 train loss  0.0321 valid loss 0.014 and accuracy 0.7031\n"
     ]
    }
   ],
   "source": [
    "training_results = train_ir(lstm_cnn_qa, optimizer, train_dt, valid_dt, validate_ir, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "familiar-telephone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV Dominio: chemistry\n",
      "accuracy: tensor([0.2851]), points: 32\n",
      "----------\n",
      "TEST Dominio: chemistry\n",
      "accuracy: tensor([0.2729]), points: 42\n"
     ]
    }
   ],
   "source": [
    "acc, points = evaluate(lstm_cnn_qa, dev_categ, trainset.encode, evaluator_ir)\n",
    "print(f'DEV Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')\n",
    "print('----------')\n",
    "acc, points = evaluate(lstm_cnn_qa, test_categ, trainset.encode, evaluator_ir)\n",
    "print(f'TEST Dominio: {CATEGORY}')\n",
    "print(f'accuracy: {acc}, points: {points}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "changing-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + f'/trained_models/lstm_cnn_qa_{CATEGORY}'\n",
    "torch.save(lstm_cnn_qa.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-royal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
